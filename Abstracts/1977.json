{"1977": [["Articles", null], ["Book Reviews", null], ["Book Reviewers", null], ["Editorial Board Page", "This article has no abstract"], ["A Bayesian Data Analysis System for the Evaluation of Social Programs", null], ["Response Errors of Nonblack Males in Models of the Stratification Process", "We assess biases due to measurement errors in structural equation models of the intergenerational transmission of socioeconomic status. Using data for nonblack males from the 1973 Occupational Changes in a Generation-II survey, we find that retrospective reports of status variables are as reliable as contemporaneous reports and that response errors are strictly random. When measurement errors are ignored, occupational returns to schooling are underestimated by about ten percent, the effects of some background variables are underestimated by as much as 19 percent, and residual variation in socioeconomic achievements is underestimated by as much as 16 percent."], ["Measuring and Testing Relative Advertising Effectiveness with Split-Cable TV Panel Data", "Various methods of estimating and testing the relative effectiveness of advertising campaigns using split-cable TV consumer panel data are examined. Sensitivities of the methods to missing observations, serial correlation, and the pattern of the expected advertising campaign impact over time are considered. The maximum likelihood estimators for both the case of no missing observations and the missing-observations case are derived, and a nonlinear model which allows for a gradual diffusion of the relative impact of the campaign is developed. For the data analyzed, the nonlinear model is best for discerning a significant difference between campaigns."], ["On the Relation between Change and Initial Value", "Given a series of consecutive measurements on a random sample of individuals, it is often of interest to investigate whether there exists a relationship between the rate of change and the initial value. Assuming that the observations deviate in a random manner from the true values, straightforward regression computations will yield biased results. It is shown that, in the case of the normal distribution, the maximum likelihood (ML) estimates of the second-order moments of the true slope and the true initial value are obtained by simple adjustments of the corresponding moments of the estimated quantities. An asymptotic formula for the standard error of the regression coefficient of slope on initial value is derived, and the methods are applied to longitudinal blood pressure data. The case with concomitant variables is discussed briefly."], ["An Empirical Stopping Rule for Debugging and Testing Computer Software", "In this article we introduce the problem of computer software reliability and discuss a probabilistic model for describing the failure of software. We suggest a procedure for estimating the parameters of the model and propose a stopping rule for debugging the software. We apply our procedures to some published data on software failures."], ["Optimum Allocation in Stratified Random Network Sampling for Estimating the Prevalence of Attributes in Rare Populations", null], ["Elasticities of Substitution among Capital and Occupations in U.S. Manufacturing", "This article presents estimates of the elasticities of substitution among capital and up to 12 sex-occupation categories of labor, as well as each input's elasticity of demand, for 12 U.S. manufacturing industries in 1960. These values are derived from a cross-section production function model using states as observations, estimated with data from the Censuses of Manufacturing and Population. The estimator is a nonlinear iterative Zellner procedure, which produces full-information maximum likelihood estimates in this particular application. The results indicate that aggregation of labor into one or two categories is inconsistent with the data in most industries and that capital-skill complementarity is not universal in U.S. manufacturing."], ["Development of a Mathematical Formula for the Calculation of Fingerprint Probabilities Based on Individual Characteristics", "A method is developed for assigning a probability to a fingerprint, including a partial print, based on the number of individual (Galton) characteristics present. A multinomial model is used, the categories of which are the individual characteristics and combinations of them. The negative of the logarithm of the probability of any particular configuration is related to the entropy function of information theory. The parameters of the model are estimated from data (fingerprints). Confidence bounds are obtained for the negative log probability of any configuration."], ["Developments in Multiple Comparisons 1966\u20131976", "This article contains a bibliography of papers on multiple comparisons between 1966 and 1976. A discussion of some of the more important developments during this period precedes the bibliography."], ["Conditional Confidence Statements and Confidence Estimators", "Procedures are given for assessing the conclusiveness of a decision in terms of a (chance) conditional confidence coefficient \u0393 that has frequentist interpretability analogous to that of a traditional confidence coefficient. Properties of such procedures are compared in terms of the distribution of \u0393. This leads to recommendations on the choice of conditioning. Also, a methodology for estimating the confidence when it depends on unknown parameter values is given. The notions of confidence are not limited to interval estimation; examples are also given in hypothesis testing and selection problems and in nonparametric and sequential settings."], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["Two Robust Alternatives to Least-Squares Regression", "We give Monte Carlo results on the performance of two robust alternatives to least-squares regression estimation\u2014least-absolute residuals and the one-step sine estimator. We show how to scale the residuals for the sine estimator to achieve nearly constant efficiency for the normal distribution across various choices of the design matrix. We compare the two estimators to least squares for nine scale-contaminated normal distributions."], ["The Estimation of the Prediction Error Variance", "Spectral methods are used to construct an estimate of the variance of the prediction error for a normal, stationary process. The estimate obtained is shown to be strongly consistent and asymptotically normally distributed. Some aspects of the computations with respect to the fast Fourier transform are considered. The latter half of the article consists of a number of simulations, based on both generated and real data, which illustrate the results obtained. The relation between the estimate and that obtained from a high order autoregression is discussed."], ["An Efficient Sequential Ranking Procedure", null], ["Likelihood and Bayesian Inference from Selectively Reported Data", "If the reported data of an experiment have been subject to selection, then inference from such data should be modified accordingly. We investigate the modification required to the face-value likelihood. In particular, we derive conditions under which no modification is necessary and the data can be taken at face value."], ["Wald's Test as Applied to Hypotheses in Logit Analysis", "For tests of a single parameter in the binomial logit model, Wald's test is shown to behave in an aberrant manner. In particular, the test statistic decreases to zero as the distance between the parameter estimate and null value increases, and the power of the test, based on its large-sample distribution, decreases to the significance level for alternatives sufficiently far from the null value."], ["Expressing the Kaplan-Meier Estimator as a Function of Empirical Subsurvival Functions", "The Kaplan-Meier estimator for the survival function in the censored data problem can be expressed for finite samples as an explicit function of two empirical subsurvival functions. This function is the natural one that expresses the survival function in terms of the sub-survival functions. As an illustration of the usefulness of expressing the Kaplan-Meier estimator in this way, the strong consistency of the Kaplan-Meier estimator is easily proved."], [null, null], ["Tolerance and Condition in Regression Computations", null], ["Computation of MINQUE Variance Component Estimates", "A matrix containing all information sufficient for the computation of MINQUE variance component estimates (Rao 1973) in random and mixed models is exhibited. The use of this matrix leads to an efficient computer algorithm which saves both computer time and memory usage."], ["A Bayesian Approach to Some Multinomial Estimation and Pretesting Problems", null], ["On the Roy-Tiku Approximation to the Distribution of Sample Variances from Nonnormal Universes", null], ["Distribution of a Sum of Weighted Chi-Square Variables", null], ["Simultaneous Confidence Bands for Percentile Lines in the General Linear Model", "This article is a generalization of the procedures developed by Steinhorst and Bowden (1971) for constructing confidence bands for the 100\u03b2th percentiles in the general linear model. Since the original procedure built these bands about a biased estimator of the 100\u03b2th precentile line, some other estimators were tried. While some improvement was noted, the results are not conclusive, suggesting that the best procedure has not been found yet."], ["Estimation of Linear Models with Time and Cross-Sectionally Varying Coefficients", "In an earlier article (Swamy and Mehta 1975), we formulated a particular decomposition for the coefficient vector in a relationship to be estimated from a time series of cross sections. Specifically, we expressed the coefficient vector as the sum of a common mean vector and two random vectors. One of these random vectors differs among individuals both at a point in time and through time, while the other differs among individuals only. In this article, we state some conditions under which the estimators of the first two moments of the coefficient vector developed in Swamy and Mehta (1975) are weakly consistent and asymptotically normal."], ["Uncertainty Functions with a Constant Rate of Reduction and Comparison of Experiments", "It is proved that an uncertainty function is a geometric mean if and only if the rate of reduction of uncertainty is independent of the prior distribution."], ["A Comparison of Two Approaches to Fixed-Width Confidence Interval Estimation", null], ["Tolerance Intervals for the Double Exponential Distribution", "A procedure is developed for obtaining upper and lower \u03b3 probability tolerance intervals for a proportion, \u03b2, of a population represented by a two-parameter Laplace or double exponential distribution. Both parameters are assumed to be unknown. The intervals are exact and are obtained by conditioning on the observed values of ancillary statistics for the parameters."], ["A Comparison of Preliminary Estimators for Robust Regression", "The minimum absolute deviation (MAD) estimator may be used as an initial, or preliminary, estimator in a robust regression procedure. Alternative estimators have been developed by Hinich and Talwar (1975) and Andrews (1974). All three estimators are related to the median, and so their respective asymptotic properties can be compared relatively easily, at least in simple models. The conclusion which emerges from such comparisons is that the asymptotic properties of the MAD estimator are, in general, superior to those of the other two estimators. However, certain small-sample properties are also important in assessing the relative merits of the different estimators."], ["On the Use of Double Sampling Schemes in Analyzing Categorical Data with Misclassification Errors", "In order to resolve the difficulties involved in inference from a sample of categorical data obtained by using a fallible classifying mechanism (usually inexpensive), we consider, as in Tenenbein (1970, 1971, 1972), the utilization of an additional sample. The second sample is subjected to a simultaneous cross-classification of its elements by the fallible mechanism and by some true (usually expensive) classifying mechanism. The setup is general; i.e., the discussion can be applied to any multidimensional cross-classified data obtained by unrestricted random sampling. Two methodologies are presented: (i) a combined maximum likelihood (ML) and least squares (LS) approach and (ii) a complete-LS approach. Both methodologies are illustrated using real data."], ["Book Reviews", null], ["Editorial Board Page", "This article has no abstract"], ["Eight Centuries of Sampling Inspection: The Trial of the Pyx", "A sampling inspection scheme bearing striking similarities to modern procedures has been in more or less continuous operation at the Royal Mint in London for about eight centuries. The history of this scheme is reviewed, and a defect in the manner in which the critical levels were set is noted. The possibility that Master of the Mint, Isaac Newton might have grasped the nature of the defect is discussed. Finally, we review the situation at the United States Mint, where similar trials have long been held, but where steps to correct the defect were taken early in the nineteenth century."], ["On the Behavior of Statistical Estimators When Sampling Accounting Populations", "Auditors usually have information on both the book amount and the audit amount available for each sample audit unit. Problems in using difference and ratio estimators, as well as some other estimators, for constructing large-sample normal confidence intervals when the population error rate is low are explored empirically in this article. The findings indicate the need for great care in using large-sample normal confidence intervals for sample sizes of 100 or 200 (sizes frequently encountered in auditing practice)."], ["Direct Approximations for Chi-Squared Percentage Points", "In contrast to the customary approximations based on normalizing transformations, direct approximations involve only simple functions of parameters (such as degrees of freedom and tail area in the chi-squared distributions). This article uses techniques of exploratory data analysis to develop direct approximations for percentage points in the commonly used portions of both tails of the chi-squared distributions with small to moderate numbers of degrees of freedom. These approximations are convenient to use, and they compare favorably in accuracy with the popular approximations based on normalizing transformations."], ["Sampling Problems in the Estimation of the Money Supply", "In this article, the selection and testing of a sample of member banks of the Federal Reserve System are described. The objectives are timely and accurate estimation of monetary aggregates for the population of member banks. This sampling problem is unusual for two reasons: the need to produce regular weekly estimates on an accelerated time schedule, and the extensive historical data available. These past data afford an opportunity to improve the precision of estimation and to test the efficacy of alternative estimators."], ["Testing a Nonlinear Regression Specification: A Nonregular Case", "A statistical test of whether an additive nonlinear term in the response function should be omitted from a nonlinear regression specification is considered. The regularity conditions used to obtain the asymptotic distributions of the customary test statistics are violated when the null hypothesis of omission is true. Moreover, standard iterative algorithms are likely to perform poorly when the data support the null hypothesis. Methods designed to circumvent these mathematical and computational difficulties are described and illustrated."], [null, null], ["On the Effect of Jury Size", null], ["Rejoinder", null], ["Formalizing Subjective Notions about the Effect of Nonrespondents in Sample Surveys", "A method is given for estimating, in a subjective sense, the effect of nonresponse in sample surveys. Based on Bayesian techniques, this method produces a subjective probability interval for the statistic that would have been calculated if all nonrespondents had responded. Background information which is recorded for both respondents and nonrespondents plays an important role in sharpening the subjective interval. Real survey data of 660 schools with 188 nonrespondents indicates that the method can be useful in practical problems. The general idea can be applied to any problem with nonrespondents or missing data."], ["Fractional Order Statistics, with Applications", "Based upon Ferguson's Dirichlet process, we introduce an order-statistic process, a technical device which may be viewed as defining a continuum of fractional order statistics for any sample size. The order-statistic process provides an alternative to the quantile function essentially based on stochastic rather than linear interpolation. Its use in large-sample theory is suggested, and a simple proof is given that the order-statistic process, suitably normalized, converges to a Gaussian process. Applications to small-sample theory and to the passage-time distribution of Yule processes are also considered, and a class of censored-data problems is related to mixtures of these processes."], ["Test Resistance", null], ["The Efficiency of Cox's Likelihood Function for Censored Data", "D.R. Cox has suggested a simple method for the regression analysis of censored data. We carry out an information calculation which shows that Cox's method has full asymptotic efficiency under conditions which are likely to be satisfied in many realistic situations. The connection of Cox's method with the Kaplan-Meier estimator of a survival curve is made explicit."], ["Stepwise Multiple Comparison Procedures", "This article proposes two new stepwise multiple comparison significance tests which control the experimentwise type I error rate and compares these tests with some existing procedures. The new (step-up) tests begin by examining the gaps between adjacent ordered sample means, then the three stretches, etc., until the range is reached. This reverses a procedure (step-down) proposed by Ryan (1960). Tables for the new tests were constructed using improved Monte Carlo techniques. A simulation study showed that one of the new step-up tests and a modification of the Ryan procedure provided significantly greater power than the commonly used Tukey honestly significant difference test."], ["On a Fundamental Theorem in Multiple Comparisons", "A result of Tukey (1953), Spj\u00f8tvoll (1971), and Einot and Gabriel (1975) concerning multiple-range tests is stated sometimes with and sometimes without an implied condition of monotonicity of the defining critical values. It is shown that this condition is not only sufficient but also necessary for the validity of this and a related result."], ["On Estimating the Variance in Sampling with Probability Proportional to Aggregate Size", null], ["A Prediction Interval Approach to Obtaining Variables Sampling Plans for Small Lots: Single Sampling from Gaussian Processes", "A prediction-interval approach is used to derive variables sampling plans applicable to finite lots. A normally distributed process is assumed, and lots ranging in size from 5 to 70 are considered. The plans are such that, with high probability, accepted lots will have zero defects (defined in terms of one-sided specification limits). Further, tabulations provide information which is useful for selecting sample size for a specified combination of lot size and acceptable quality level. Substantial savings in sample size can be achieved by using variables plans in place of the comparable hypergeometric sampling plans."], ["Sequential Procedures for Detecting Parameter Changes in a Time-Series Model", "Procedures are proposed for monitoring forecast errors in order to detect changes in a time-series model. These procedures are based on likelihood ratio statistics which consist of cumulative sums. An extension of Page's method is presented which tests for changes in the parameter values of autoregressive integrated moving average (arima) models. The distributional properties of the statistics are approximated under the assumption that the series follows an integrated autoregressive moving average model. This approximation is based on the limiting Wiener process. An example is also given."], ["More on Computational Accuracy in Regression", "Issue is taken with a previous article which examines Longley's analysis of computation error in regression models. Specifically, the singular value decomposition is used to analyze a set of data which relates to employment levels. This decomposition is used to analyze near multicollinearity in the data. It is suggested that a previous Monte Carlo study of this problem is noninformative, misleading, and possibly irrelevant."], ["Comment", null], ["Rejoinder", null], ["A Note on the Acceptability of Regression Solutions: Another Look at Computational Accuracy", "This note examines the experiment performed by Beaton, Rubin, and Barone (1976) to study the effect of rounding errors in published figures, when these data are used in regression analysis. The experiment could be vitiated by the fact that the error introduced in the trend variable is by no means trivial when one measures the data in deviation from the mean. For this reason, the results presented in Beaton, Rubin, and Barone (1976) do not contain enough evidence to suggest \u201cthat it is extremely unlikely that the unperturbed solution\u201d (p. 161) of the Longley model is the correct one."], ["A Power Approximation for the Chi-Square Goodness-of-Fit Test: Simple Hypothesis Case", null], ["A Comparative Study of Several Robust Estimates of Slope, Intercept, and Scale in Linear Regression", null], ["Biased Estimation in Regression: An Evaluation Using Mean Squared Error", "A mean squared error criterion is used to compare five estimators of the coefficients in a linear regression model: least squares, principal components, ridge regression, latent root, and a shrunken estimator. Each of the biased estimators is shown to offer improvement in mean squared error over least squares for a wide range of choices of the parameters of the model. The results of a simulation involving all five estimators indicate that the principal components and latent root estimators perform best overall, but the ridge regression estimator has the potential of a smaller mean squared error than either of these."], ["Weighted Least-Squares Analysis of Several Univariate Bradley-Terry Models", "The approach of Grizzle, Starmer, and Koch (1969) to analyzing categorical data using linear and loglinear transformations is applied to the analysis of univariate paired and triple comparison experiments. This method of analysis produces noniterative weighted least-squares estimates of the preference ratings corresponding to the treatments under test and allows for testing hypotheses relative to their values within the framework of the general linear hypothesis. Further, the technique produces estimates of the preference ratings which are linear on the log scale within which Bradley (1965) defined his model. Examples with and without ties or order effects for paired comparison experiments and an example of a triple comparison experiment are presented."], ["Some Properties of Tests for Specification Error in a Linear Regression Model", "This article considers the test reset which is intended to detect a nonzero mean of the disturbance in a linear regression model. Analysis of an approximation to the test statistic's distribution and Monte Carlo experiments reveal that the power of the test may decline as the size of the disturbance mean increases. However, the possibility is remote and declines with increasing sample size. Alternative sets of test variables are considered, and their effect on the power of the test is studied in Monte Carlo experiments. The best set seems to be composed of powers of the explanatory variables."], ["A Family of Concepts of Dependence for Bivariate Distributions", "A family of concepts of stochastic dependence for bivariate distribution functions is introduced. Each concept gives rise to a family of bivariate distribution functions. We show the equivalence of some of these families with families of positively dependent distribution functions, which are known in the literature, and characterize some of them by notions from reliability theory. Interrelations among the various families are studied, and some moment inequalities are derived. Some examples and applications are discussed."], ["On the Representation of Ignorance", null], ["Minimax Purposive Survey Sampling Design", "The linear regression superpopulation model for survey sampling allows a formulation of the survey design problem which is close to optimum experimental design theory. This article introduces an alternative criterion to that of Royall (1970). A sampling design can be chosen to minimize the maximum mean squared error (mse) of \u201cprediction\u201d over the unsampled units. An upper bound for this maximum mse is derived and an algorithm given for obtaining samples satisfying the bound. The efficiency of these minimax designs for estimation of the population total is compared with the best designs in this case\u2014namely the balanced designs of Royall."], ["Distribution of Q When Testing Equality of Matched Proportions", null], ["An Algorithm for the Discrete Fisher's Permutation Test", "An algorithm, especially suitable for a computer, is presented for carrying out Fisher's two sample permutation test for integer-valued data with ties. It is shown that the same method can be applied to carry out the permutation Wilcoxon test in the presence of ties using average ranks. Some numerical examples are given."], ["Nonparametric One-Sided Tests in Multivariate Analysis with Medical Applications", null], ["Estimating the Size of a Truncated Sample", null], ["Maximin Tests of Randomness against Ordered Alternatives: The Multinomial Distribution Case", null], ["Factors for One-Sided Tolerance Limits for Balanced One-Way-ANOVA Random-Effects Model", "A technique based on the noncentral t distribution for obtaining one-sided tolerance limits for a balanced one-way-anova random-effects model is developed. These limits are such that the probability is \u03b3 that at least a proportion p of the population consisting of very many specimens from very many batches exceeds the calculated lower limit. A few selected tables are given, and an example illustrates the use of the derived tolerance factors."], ["A Remark on the Difference between Sampling with and without Replacement", null], ["Book Reviews", null], ["Corrigenda", null], ["Editorial Board Page", "This article has no abstract"], ["Malaria and Mortality", "Controversy has arisen concerning the extent near eradication of malaria affects mortality in tropical countries. Guesses of malaria's contribution to the classic fall in mortality in post-war Sri Lanka have varied from zero to 100 percent, while more serious estimates range from 21 percent (Gray 1974) to 48 percent (Newman 1965, 1970). In this article a general model is devised in which the previous estimating equations may be embedded. The Box-Cox approach to nonlinear regression analysis is then used to estimate close approximations to this model. The method yields a \u201cbest\u201d estimate of 44 percent but also yields fairly wide margins of error."], ["Autoregressive Integrated Moving Average (ARIMA) Models for Birth Forecasting", "Autoregressive integrated moving average (ARIMA) models are developed for birth time series, and their relationship with classical models for population growth is investigated. Parsimonious versions for the ARIMA models are obtained which retain the most important pieces of information including the length of generation of the population. The technique is applied to birth time series data for Norway."], ["Probabilistic Clustering for Attributes of Mixed Type with Biopharmaceutical Applications", "A procedure is presented for finding clusters of individuals in situations where every individual is classified with respect to each of a set of attributes, which may have ordered states (interval or ordinal) or nonordered states. The procedure is based on a probabilistic measure of similarity generated entirely from the given data. It can use but does not require measurement data, permits mixtures of kinds of attributes, and has been successfully used to reveal nonindependence of attributes as well as to cluster for taxonomic purposes. It appears to give results with measurement data nearly identical to those of methods that require such data."], ["The Use of Linear-Model Methodology to Rate High School or College Football Teams", "A procedure for rating high school or college football teams is developed by applying linear-model methodology to the point spread for each game. The model includes effects for the home-field advantage and for the mean performance levels of the participating teams. The procedure can be modified to use only win-loss information or to ignore victory margins greater than a given margin. When applied to the results of the 1975 college football season, it produced predictions whose accuracy compares favorably with those of sportswriters and bookmakers."], ["Measurement Errors in the Estimation of Home Value", "Home value plays an important role in a variety of fields of research. In this paper, three commonly used measures of home value are evaluated and compared using a framework developed by J\u00f6reskog and Goldberger (1975) for estimation of causal models containing unobserved variables. The paper extends ideas presented by Kain and Quigley (1972) and Kish and Lansing (1954)."], ["Estimating the Total Overstatement Error in Accounting Populations", "Auditors wishing to estimate the total amount of errors in a set of accounts have tended to use estimation procedures which rely on approximate normality for large sample sizes. Since this reliance is often not well-founded for sample sizes used in auditing practice, efforts have been made to circumvent this difficulty. This paper will briefly describe these efforts and then present a new approach based on the multinomial probability distribution which yields confidence bounds with known confidence levels for all sample sizes."], ["Stochastic Interpretation of 2\u00d72 Classification Tables", "Procedures which classify individuals into discrete categories are often evaluated by the fraction of individuals correctly classified. If the individual behavior is truly stochastic rather than deterministic, the expected fraction of correct classifications would be less than one, even when the procedure is based upon perfect estimates of every individual's probability of belonging to a category. For the binary case of two categories, the expected fraction which is correctly classified is between 50 and 100 percent. The exact value depends upon the mixing distribution of probabilities in the population."], ["Sampling Behavior of Tests for Correlation in Two-Way Contingency Tables", null], ["Probabilities Based on Circumstantial Evidence", "A recent paper by Smith and Charrow (1975) shows how easily misunderstandings about statistical independence can confuse assessment of the extent to which a combination of unusual traits reinforces evidence against a suspect. A simple example illustrates the importance to the calculation of a probability of exact specification of the way in which data and ancillary information are obtained."], ["Comment", null], ["Maximum Likelihood Approaches to Variance Component Estimation and to Related Problems", "Recent developments promise to increase greatly the popularity of maximum likelihood (ml) as a technique for estimating variance components. Patterson and Thompson (1971) proposed a restricted maximum likelihood (reml) approach which takes into account the loss in degrees of freedom resulting from estimating fixed effects. Miller (1973) developed a satisfactory asymptotic theory for ml estimators of variance components. There are many iterative algorithms that can be considered for computing the ml or reml estimates. The computations on each iteration of these algorithms are those associated with computing estimates of fixed and random effects for given values of the variance components."], ["Comment", null], ["Rejoinder", null], ["Confidence Intervals for Bisquare Regression Estimates", null], ["On the Elimination of Nuisance Parameters", "Eliminating nuisance parameters from a model is universally recognized as a major problem of statistics. A surprisingly large number of elimination methods have been proposed by various writers on the topic. In this article we propose to critically review two such elimination methods. We shall be concerned with some particular cases of the marginalizing and the conditioning methods. The origin of these methods may be traced to the work of Sir Ronald A. Fisher. The contents of the marginalization and the conditionality arguments are then reexamined from the Bayesian point of view. This article should be regarded as a sequel to the author's three-part essay (Basu 1975) on statistical information and likelihood."], ["Multivariate Generalization of Kendall's Tau with Application to Data Reduction", "The usual bivariate Kendall's tau estimates the probability of concordance of point pairs minus the probability of discordance. This paper presents a multivariate generalization of this idea. The multivariate versions can be used to investigate dimensions (in the multicollinearity spirit) in the data. Examples are given."], ["On Estimating the Number of Vital Events in Demographic Surveys", "An examination is made of the effectiveness of the Chandrasekar-Deming technique for estimating the number of vital events using both the registration (continuous recording) of events and a periodic retrospective survey. It is shown that, under a general model for response errors, the technique may produce estimates that are considerably biased downwards. A comparison is made with a number of other estimators. The possibility of improving results through double sampling is explored."], ["A Class of Designs for Sequential Clinical Trials", "In a situation comparing the effectiveness of two clinical treatments, eligible subjects come to an experimental site sequentially and must be treated at once. In order to reduce different kinds of experimental bias and also increase the precision of inferences about treatment effects, a class of designs which offers a compromise between perfect balance and complete randomization is proposed and analyzed in this article. These new designs have the desirable property of forcing a small-sized experiment to be balanced while tending toward a complete randomization scheme as the size of the experiment increases."], ["Robust Univariate Test of Symmetry", null], ["Robustness of Location Estimators under Changes of Population Kurtosis", null], [null, null], ["Estimating the Linear Discriminant Function from Initial Samples Containing a Small Number of Unclassified Observations", null], ["The Joint Distribution of the Standardized Row Sums of Squares from a Balanced Two-Way Layout", null], ["On the Asymptotic Variances of \u00fb Terms in Loglinear Models of Multidimensional Contingency Tables", "Loglinear models are classified as direct or indirect depending on whether the maximum likelihood estimates of cell values are explicit functions of the sufficient statistics or not. For saturated (hence, direct) models, Goodman (1970) and Bishop, Fienberg, and Holland (1975) used the \u03b4 method to calculate the asymptotic variances of various \u00fb terms in the loglinear models. In the present paper, this approach has been generalized to direct unsaturated hierarchical loglinear models. General rules for determining closed form expressions for asymptotic variances in such situations are obtained; bounds for the asymptotic variances of \u00fb terms in indirect models are considered; and these rules are compared with other methods of producing asymptotic variances."], ["Improvement of Kernel Type Density Estimators", "Estimation of the value of a density function at a point of continuity using a kernel-type estimator is discussed and improvements of the technique are presented. The generalized jackknife method is employed to reduce the asymptotic and small sample mean square error and bias of these estimators. The procedure presented has the flexibility to afford the user a choice between bias reduction, variance reduction, or both."], ["All-Bias Designs for Spline Functions Joined at the Axes", null], ["Exact Linear Restrictions on Parameters in the General Linear Model with a Singular Covariance Matrix", null], ["Some Simplifying Results on BLUEs", null], ["On Admissibility and Completeness of Linear Unbiased Estimators in a General Linear Model", "Admissibility and completeness of linear unbiased estimators in a linear model with general covariance structure are examined. Under rather unrestrictive conditions, a minimal complete class of linear unbiased estimators is described."], ["A Note on the Approximation of Arbitrary Distributed Lag Structures by a Modified Almon Lag", "A uniform approximation of any arbitrary lag structure can be achieved from a distributed lag formulation which is a combination of the Almon and geometric lag formulations."], ["Estimation of a Time-Truncated Exponential Parameter Used in Life Testing", null], ["Upper and Lower Probability Inferences Pertaining to Poisson Processes", "A general system of inference which leads to upper and lower posterior distributions has been proposed by Dempster (1966, 1968a, 1968b). This general theory of inference is applied to various estimation problems arising in Poisson processes. In particular, the emphasis is on the estimation of the parameter of the process and on the prediction of the number of future events, given the observed data. In this article, all upper and lower probability inferences are generated by random intervals"], ["Inner Statistical Inference", "For any linear model there is, according to an invariance argument, a uniquely defined prior representing ignorance, which will be called the inner prior. It is shown that the corresponding posterior probabilities are weighted averages of conditional confidence levels. This frequency interpretation compares favorably with the usual interpretation of confidence levels as unconditional probabilities of coverage. Of particular interest to users of statistical methods is that inner posterior intervals are always shorter than the corresponding confidence intervals and, sometimes, dramatically so."], ["Nonparametric Estimation of Ratio of Scale Parameters", null], [null, null], [null, null], ["Book Reviews", null], ["Corrigenda", null], ["Editorial Board Page", "This article has no abstract"], ["What Lies Ahead?", null], ["Relationships\u2014and the Lack Thereof\u2014Between Economic Time Series, with Special Reference to Money and Interest Rates", "Extensions of time-series modeling procedures of Box and Jenkins [5] reveal that numerous economic variables which are generally regarded as being strongly interrelated may with equal validity, based on recent empirical evidence, be regarded as independent or only weakly related. Differences between these results and the bulk of econometric literature are attributed to the failure of the latter to satisfactorily account for autocorrelation. Due to limitations in the data, it is concluded that in many instances where economic relationships clearly do exist, econometric or other empirical means cannot reliably enable their existence to be ascertained."], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["Covariance Analysis of Heart Transplant Survival Data", "This paper presents a number of analyses to assess the effects of various covariates on the survival of patients in the Stanford Heart Transplantation Program. The data have been updated from previously published versions and include some additional covariates, such as measures of tissue typing. The methods used allow for simultaneous investigation of several covariates and provide estimates of the relative risk of transplantation as well as significance tests."], ["Considerations in Measuring Partial Association for Ordinal Categorical Data", null], ["Comparison of Stopping Rules in Forward \u201cStepwise\u201d Regression", null], ["Two Methods for Examining the Stability of Regression Coefficients", "This paper investigates the power of two methodologies, the tests of Brown, Durbin, and Evans [2] and variable parameter regression, to detect several varieties of instability in the coefficients of a linear regression model. The study reported by Khan [10] on the stability of the demand for money is replicated with variable parameter regression, and his results are in part questioned and in part sharpened."], ["Cubic Splines as a Special Case of Restricted Least Squares", "The standard cubic spline regression method is shown to be a special case of the restricted least-squares estimator. The equivalence of the two procedures under a common set of restrictions is proved. The greater flexibility of the restricted least-squares estimator in terms of the number of restrictions and tests of hypotheses that can be utilized is illustrated by an application to a set of data that has been previously analyzed by the spline method."], ["Maximum Likelihood Estimation in Random Coefficient Models", "Previous Monte Carlo studies examining properties of estimators in random coefficient models have been hindered in part by computational difficulties. In particular, determination of maximum likelihood estimators appears sensitive to the computational algorithm used. In a small Monte Carlo experiment, several distinctly motivated algorithms are examined with respect to accuracy and cost in searching for global and local maximum likelihood parameter estimates. A noncalculus oriented approach offers promise. When compared with other estimators, maximum likelihood estimators, so determined, appear to be statistically relatively efficient."], ["A Table of Exact Confidence Limits for Differences and Ratios of Two Proportions and Their Odds Ratios", null], ["A Simulation Study of Alternatives to Ordinary Least Squares", "Estimated regression coefficients and errors in these estimates are computed for 160 artificial data sets drawn from 160 normal linear models structured according to factorial designs. Ordinary multiple regression (OREG) is compared with 56 alternatives which pull some or all estimated regression coefficients some or all the way to zero. Substantial improvements over OREG are exhibited when collinearity effects are present, noncentrality in the original model is small, and selected true regression coefficients are small. Ridge regression emerges as an important tool, while a Bayesian extension of variable selection proves valuable when the true regression coefficients vary widely in importance."], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["Statisticians are Fairly Robust Estimators of Location", "The performance of the outlier rejecting statistician is monitored and compared with those of several robust estimators of location. The comparisons are made by plugging a number of statisticians' location estimates into a Monte Carlo experiment. The result is that the statistician staves off the potential disasters of ordinary least squares, but he can be beaten."], ["Bayes Linear Estimators of the Intensity Function of the Nonstationary Poisson Process", null], ["Identification of Dynamic Regression (Distributed Lag) Models Connecting Two Time Series", "A methodology is introduced for identifying dynamic regression or distributed lag models relating two time series. First, specification of a bivariate time-series model is discussed, and its relationship to the usual dynamic regression model is indicated. Then, a two-stage identification procedure is presented which involves fitting univariate time-series models to each series, and identifying a dynamic shock model relating the two univariate model innovation series. The models obtained at these two stages are combined to identify a dynamic regression model, which may then be fitted in the usual ways. Two systems of economic time series illustrate the methodology."], ["Generalized Inverses, Wald's Method, and the Construction of Chi-Squared Tests of Fit", "Wald's method constructs test statistics having chi-squared limiting distributions from estimators having nonsingular multivariate normal limiting distributions, using the inverse of the covariance matrix of the limiting distribution. This method is here extended to singular multivariate normal limiting distributions by use of generalized inverses. The generalized Wald's method is then applied to give a quite general solution to the problem of constructing chi-squared type statistics for testing fit to a parametric family when unknown parameters are estimated in various ways."], ["Is the Tail Area Useful as an Approximate Bayes Factor?", "Inequalities are given relating the tail area for a nested sharp hypothesis to the Bayes factor based on the event of \u201csignificance\u201d considered as data. This Bayes factor based on an insufficient statistic is, in turn, expressed as a weighted average of full-data Bayes factors. Lindley's \u201cstatistical paradox\u201d is generalized and other comparisons made in the normal sampling context. A new Bayesian interpretation is given for the traditional two-tailed critical level. An example and the discussion suggest a negative answer to the question in the title."], [null, null], ["Comment", null], ["Rejoinder", null], ["On the Unique Consistent Solution to the Likelihood Equations", "Existence of a unique consistent solution to the likelihood equations is obtained as a consequence of the Inverse Function Theorem. The approach differs from those already in the literature by showing existence and uniqueness in one argument. The argument deals directly with the vector parameter case rather than with extending single parameter arguments."], ["On the Effect of Stratification When Two Stratifying Variables are Used", "Most of the literature on survey sampling deals with a single stratifying variable. In this paper an attempt is made to study the effect of using two stratifying variables. We present an approximation to the variance of the study variable under the assumption of a linear regression on the two stratifying variables. This approximation depends only on the number of strata, the simultaneous density of the stratifying variables, and the correlations between the study variable and each of the stratifying variables. The results indicate that in many practical situations the gain from using two stratifying variables over one is nontrivial."], [null, null], ["Recovery of Interblock Information for Designs with Groups of Correlated Blocks", "A procedure is presented for estimating the dispersion matrix of block totals in an incomplete block design where blocks can be divided into groups such that those from different groups are independent and those from the same group are dependent. Equal block variances and equal nonzero covariances are assumed. It is shown that when the estimated dispersion matrix is used to obtain a weighted least-squares interblock estimator of treatment means, both that estimator and the combined intra-interblock estimator converge in mean square to their respective BLUEs more rapidly than the BLUEs converge to the vector of treatment means."], ["On Characterizations of the Exponential and Geometric Distributions by Expectations", "This paper presents a characterization of the exponential distribution in terms of the means of the left-truncated values of the random variable concerned. This characterizing property leads to the Cauchy equation just as in the case of the lack of memory characterization. While the latter characterization assumes somewhat less easily accessible information concerning the probability distribution, the former only requires more readily available information regarding the expected values. The present characterization will be particularly useful in testing exponentiality for a failure model. A similar characterization is given for the geometric distribution."], ["Estimation of Quantiles of Exponential Distributions with Minimum Error in Predicted Distribution Functions", "We consider the problem of estimating the quantiles of a one-parameter exponential distribution. Using the estimated quantiles to predict the distribution function, and attempting to minimize mean square errors for these predicted probabilities rather than the quantiles themselves, we are led to estimators differing from the natural ones obtained by appropriate scaling of the estimated mean of the distribution. The form of these estimators is studied for complete and censored samples, and also for the optimal single order statistic. Numerical comparisons are made, leading to the conclusion that for moderate sample sizes the estimators studied here are considerably more efficient than the natural ones, particularly for high quantiles."], [null, null], ["A Two-Sample Test for Independence in 2\u00d72 Contingency Tables with Both Margins Subject to Misclassification", "A double sampling scheme is considered for estimation and testing under misclassification in both margins of a 2\u00d72 contingency table; the matrix of misclassification probabilities is assumed to be unknown and nonsingular. Maximum likelihood estimators are given for the error-free and misclassification probabilities. Numerical methods are utilized to obtain maximum likelihood estimates under the independence hypothesis and the regularity conditions are affirmed for the asymptotic properties of the estimates to hold. The log-likelihood ratio statistic is shown to be asymptotically distributed as a chi-square. Computer simulations indicated important considerations for testing under double margin misclassification."], ["An Approximate Test of Markov Chain Lumpability", null], ["Testing a Sequence of Observations for a Shift in Location", null], ["Two-Stage Least Squares: In Which Direction Should the Residuals Be Minimized?", "A structural equation in a complete system may be written with the coefficient of one endogenous variable as unity and the coefficients of the other endogenous variables as parameters. To estimate these parameters two-stage least squares is usually applied by minimizing residuals in the direction of the first variable. In this paper, when there is one such parameter, that procedure is compared with adapting two-stage least squares to minimize residuals in the direction of the second endogenous variable. Estimation of the slope of a linear functional relationship by using least squares to minimize residuals in alternative directions is also treated."], ["Robustness of Stein's Two-Stage Procedure for Mixtures of Normal Populations", "Explicit expressions for the level of significance and power of Stein's two-stage hypothesis testing procedure are derived when the normal population is mixed with another normal population differing in the mean. Approximate expansions for these expressions have been obtained, and numerical studies of the size have been carried out using the expansions. Some numerical indication of the accuracy of the approximations has also been obtained. Stein's two-stage procedure is quite robust against mixtures of normal populations differing in location parameters. Similar conclusions can be drawn regarding the coverage probabilities of confidence intervals generated by this procedure."], ["Optimum Partial Sequential Tests for Two-Sided Tests of the Binomial Parameter", "An optimum partial sequential procedure for testing a null hypothesis concerning the binomial parameter with a two-sided alternative hypothesis is described. Formulas for its operating characteristic and average sample number functions are derived. By approximating an Armitage procedure by a special case of this partial procedure, approximate values can be obtained for his operating characteristic and average sample number functions."], ["On a Class of Partially Sequential Two-Sample Test Procedures", "A class of test procedures is proposed for the two-sample setting when one of the samples has a fixed sample size, and the second is obtained by an inverse binomial sequential sampling scheme. These procedures allow either a classical approach or a completely nonparametric attack to a wide variety of two-sample problems, Properties of the tests are discussed, Including limiting distributions as the fixed sample size tends to infinity, and the capability of obtaining asymptotic power restrictions against specified alternatives of interest. Criteria for selecting a particular procedure are discussed."], [null, null], ["A Differential Equation Approach to Linear Combinations of Independent Chi-Squares", null], [null, null], ["Intermediate Simultaneous Inference Procedures", null], ["Book Reviews", null], ["Technical Reports Available", null], ["Editorial Board Page", "This article has no abstract"]]}