{"1982": [["Bayesian Optimization of the Estimation of the Age Composition of a Fish Population", "To estimate the age distribution of a fish population, a two-phase stratified sample design is proposed. Bayesian methods are employed to determine (a) optimal estimators of the desired population proportions; and (b) the optimal choice of second-phase sample sizes subject to a fixed budget. A summary of the results of some numerical examples is presented. These examples demonstrate typical expected gains obtained by using the Bayesian optima as compared to alternative choices of second-phase sample sizes suggested in the substantive literature."], ["Round Robin Analysis of Variance via Maximum Likelihood", "A class of two-way random-effects models is presented for analyzing data that arise in a large variety of round robin designs. Examples of such designs can be found in numerous games, tournaments, and social interactions. The proposed models provide information not only about individual differences but also about the mutual contingency of the behaviors of interaction dyads. The statistical inference of the linear effects is discussed and a converging algorithm based on the EM algorithm is proposed for obtaining the maximum likelihood estimates of the covariance components. A balanced data set is analyzed using the methodology developed."], ["Estimation of Nonlinear Learning Models", "The article develops the structure and estimates the parameters of a nonlinear learning model applicable to research designs in which students are tested at the beginning and end of a course of study. A student's precourse score is an error-ridden proxy for his precourse aptitude. As a remedy for this problem, the article combines a probit model of test score outcomes, a learning function, and a linear equation relating aptitude to demographic characteristics to deduce the exact test score distribution. An empirical example of maximum likelihood estimation of the model's parameters is presented."], ["The Effects of Asymmetric Filters on Seasonal Factor Revisions", "Recent data seasonally adjusted by moving average methods are subject to revisions due to differences in the properties of the linear filters for the same seasonal adjustment when later data become available. This article introduces a measure of the total revision associated with the concurrent and forecasting seasonal filters and applies it to the Census Method II-X-11 variant and the X-11-ARIMA method. To consider the fact that the spectrum of many economic indicators tends to have higher peaks at the lower seasonal frequencies than at the higher, the revision measures are calculated both over all the seasonal frequencies and over selected seasonal frequency intervals."], ["On the Design of Seasonal Adjustment Methods using Linear Programming Techniques", "The objectives of the seasonal adjustment of monthly economic time series are discussed. The design of seasonal adjustment methods of the moving average type is formulated in terms of a linear programming problem. A moving average is designed, using this technique, to seasonally adjust current data. The designed moving average is compared to the X-11 current data moving average in both the time and the frequency domains."], ["Detecting Outliers in Time Series Data", null], [null, "We consider the problem of estimating a probability density from observations from that density which are further contaminated by random errors. We propose a method of estimation using spline functions, discuss the numerical implementation of the method, and prove its consistency. The problem is motivated by the analysis of DNA content obtained by microfluorometry, and an example of such an analysis is included."], ["Playing Safe with Misweighted Means", null], ["A Fast and Efficient Algorithm for the Estimation of Parameters in Models with the Box-and-Cox Transformation", null], ["On Graphical Procedures for Multiple Comparisons", null], ["Statistical Evidence of Discrimination", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["The Powers and Strengths of Tests for Multinomials and Contingency Tables", null], ["Some Models for the Analysis of Association in Multiway Cross-Classifications Having Ordered Categories", "Goodman recently presented a class of models for the analysis of association between two discrete, ordinal variables. The association was measured in terms of the odds ratios in 2 \u00d7 2 subtables formed from adjacent rows and adjacent columns of the cross-classification, and models were devised that allowed the odds ratios to depend on an overall effect, on row effects, on column effects, and on other effects. This article presents some generalizations of this approach appropriate for multiway cross-classifications, including (a) models for the analysis of conditional association, (b) models for the analysis of partial association, and (c) models for the analysis of symmetric association. Three cross-classifications are analyzed with these models and methods, and rather simple interpretations of the association in each are provided."], ["A Time Series Analysis of Binary Data", null], ["Updating Subjective Probability", null], ["An Inconsistent Maximum Likelihood Estimate", "An example is given of a family of distributions on [\u2014 1, 1] with a continuous one-dimensional parameterization that joins the triangular distribution (when \u0398 = 0) to the uniform (when \u0398 = 1), for which the maximum likelihood estimates exist and converge strongly to \u0398 = 1 as the sample size tends to infinity, whatever be the true value of the parameter. A modification that satisfies Cram\u00e9r's conditions is also given."], ["Cluster Inference by using Transitivity Indices in Empirical Graphs", "A random graph model is introduced for similarities observed between the objects sampled from an unknown cluster structure. We investigate this model and show how some common transitivity indices in empirical graphs can be used for making statistical inferences about cluster structures."], ["A Hybrid Clustering Method for Identifying High-Density Clusters", null], ["The Effect of Two-Stage Sampling on Ordinary Least Squares Methods", null], ["Repeated Significance Testing for a General Class of Statistics Used in Censored Survival Analysis", "The asymptotic joint distribution of a class of sequentially computed statistics used in survival analysis is derived when the individuals under study enter serially and are subject to random loss to follow-up. These results are used for constructing repeated significance tests over real time."], ["Two-Sample Repeated Significance Tests Based on the Modified Wilcoxon Statistic", "The asymptotic distribution theory of sequentially computed modified-Wilcoxon scores is developed for two-sample survival data with random staggered entry and random loss to follow-up. The asymptotic covariance indicates generally dependent modified-Wilcoxon increments, contradicting (the authors' reading of) Jones and Whitehead (1979). A repeated significance testing procedure is presented for testing the equality of two survival distributions based on the asymptotic theory. The early stopping properties of this procedure are illustrated by a prostate cancer example."], ["A Test of Incomplete Additivity in the Multiplicative Interaction Model", null], ["A Comparison between Maximum Likelihood and Generalized Least Squares in a Heteroscedastic Linear Model", "We consider a linear model with normally distributed but heteroscedastic errors. When the error variances are functionally related to the regression parameter, one can use either maximum likelihood or generalized least squares to estimate the regression parameter. We show that likelihood is more sensitive to small misspecifications in the functional relationship between the error variances and the regression parameter."], ["Estimating Latent Variable Systems When Specification is Uncertain: Generalized Component Analysis and the Eliminant Method", "This article argues that, to relieve the specification difficulties that frequently accompany latent variable models, a first application should in most cases employ an estimator that makes no assumption about the nature of the unobservables. The two possibilities are generalized component analysis, with the unobservables treated as incidental parameters; and the eliminant method, where they are removed by transformation of the model before estimation. It is shown that these are equivalent, whichever transformation is used, but that the latter has substantial practical advantages."], ["The Effect of Variable Correlation on the Efficiency of Seemingly Unrelated Regression in a Two-Equation Model", "The efficiency gain of seemingly unrelated regression (SUR) relative to OLS is a decreasing function of correlation of variables across equations. This article examines the efficiency gain for an individual coefficient in a two-equation model. It is seen that the effect of correlation among variables across the equations greatly depends on the multicollinearity already existing within an equation. In particular, the major factor determining the efficiency gain of SUR for the coefficient on an individual variable is not the correlation between that variable and those in the other equation. Rather, it is the correlation between the latter and the residuals obtained by regressing the variable in question on the remaining variables in its own equation."], ["On the Effects of Moderate Multivariate Nonnormality on Roy's Largest Root Test", null], ["Inference Based on Simple Rank Step Score Statistics for the Location Model", "A class of estimation procedures that are robust, relatively efficient, and yet computationally simple is proposed for the one- and two-sample location problems. Particular emphasis is placed on the problem of determining confidence intervals, a topic that has seen limited exposure in the literature. As a by-product, some interesting point estimates are obtained. A class of score functions that are ordinary step functions is considered for the location model. Point estimates and confidence intervals are obtained by inverting the corresponding rank statistics. Efficiency and robustness properties of the procedures are investigated. Simple computational schemes for the estimates and intervals are provided."], ["Prediction and Power Transformations When the Choice of Power is Restricted to a Finite Set", null], [null, "Consider a polynomial regression situation on an interval and also a robustness-type formulation of Stigler's. A technique involving canonical moments is discussed and some explicit solutions are given."], ["On Sample-Size Selection and the Evaluation of Discriminability in the Model Choice Problem", null], ["A Note on Strong Unimodality of Order Statistics", "Order statistics from a strongly unimodal distribution are strongly unimodal."], ["Ancillarity Principle and a Statistical Paradox", null], ["Stein's Paradox is Impossible in the Nonanticipative Context", null], ["Book Reviews", null], ["Corrigenda", null], ["Editorial Board Page", "This article has no abstract"], ["Growth Kinetics of Glioma Cells", "Three experiments involving the growth of tumor cells in an organ culture system are described. The fraction of labeled mitoses, the labeling index, and the grain count are measured in each of these experiments. The data and the statistical analyses involving skewed logistic regression, branching process theory, and two-phase linear regression are presented."], ["Nonadditivity in a Two-Way Classification: Is it Interaction or Nonhomogeneous Variance?", "Nonadditivity in a two-way table with one observation per cell may be due either to row- or to column-related nonhomogeneous variance or to interaction between the row and column factors. A general model that can detect both of these types of nonadditivity is discussed. The data alone are not sufficient to distinguish between interaction and row- or column-related nonhomogeneous variance when there is one observation per cell. A study of the fitted coefficients in the proposed model together with the scientific background of the problem can, however, provide the data analyst with the information necessary to develop a useful interpretation for the observed nonadditivity. Examples are included to illustrate the proposed methodology. In one example, involving the effects of four varieties of wheat in 13 locations, it is shown that the variety-related nonhomogeneous variance detected by several authors is more usefully interpreted as a level-dependent interaction due to the differences among the yields of the different varieties of wheat being larger in those locations that have higher yields."], ["Calendar Effects in Monthly Time Series: Modeling and Adjustment", "Most monthly time series that represent a total of some variable for each month contain calendar effects due to changing month length, day-of-the-week effects, and holidays. It is important to remove the calendar variation to allow an effective assessment of the variation due to important factors. New procedures for calendar adjustment are presented in this article. A plausible model for the daily data is used to derive a model for the monthly data in which the power transformed, month-length corrected data are equal to trend plus seasonal plus calendar plus irregular. The procedure for fitting the calendar component in the monthly model is (a) divide the aggregated monthly data by month length and multiply by 30.4375, the average month length; (b) choose a power transformation; (c) remove trend and seasonal components; (d) estimate the calendar parameters by robust regression. Since the model is only a hypothesis it is important to check its validity. This can be done by various residual plots in the regression analysis and by using spectrum analysis and time-domain graphical methods to detect residual calendar effects in the adjusted series. This approach is compared to the X-11 calendar estimation procedures."], ["Using Time-Series and Cross-Section Data to Estimate a Production Function with Positive and Negative Marginal Risks", "Two production-function models with error components for time and firms and a heteroscedastic disturbance are proposed. Unlike previous models, these two permit the variance of output to increase or decrease as one of the inputs is increased. When the models and some suggested estimators are applied to the pastoral zone of eastern Australia, the results indicate that labor, water, and possibly fencing, are likely to reduce the variance of wool production; and that sheep, and buildings and land, are likely to increase the variance."], ["Specification of Economic Time Series Models Using Akaike's Criterion", null], ["Judgments of Circle Sizes on Statistical Maps", "Symbols whose sizes code a variable are often superimposed on a map to show how the value of the variable changes geographically. In many cases the areas of the symbols are proportional to the values of the variable. But previous psychological experiments indicate that people's judgments of area typically are not proportional to area, but rather to area raised to a power less than one. In many of these studies, however, the symbols are presented one at a time. Here we describe an experiment that tests whether this experimental laboratory result extends to statistical maps. We had 24 viewers judge sets of circles presented simultaneously, either with or without maplike grid ticks, labels, scale, and border. With these multiple-circle displays, judgments were related to actual area by power functions with an average exponent close to one, implying that it is appropriate to code symbols by area on statistical maps."], ["Diversity as a Concept and its Measurement", "This paper puts forth the view that diversity is an average property of a community and identifies that property as species rarity. An intrinsic diversity ordering of communities is defined and is shown to be equivalent to stochastic ordering. Also, the sensitivity of an index to rare species is developed, culminating in a crossing-point theorem and a response theory to perturbations. Diversity decompositions, analogous to the analysis of variance, are discussed for two-way classifications and mixtures. The paper concludes with a brief survey of genetic diversity, linguistic diversity, industrial concentration, and income inequality."], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["Analysis of Dispersion of Multinomial Responses", "In analogy to analysis of variance for linear models, analyses of dispersion for loglinear models for multinomial responses are constructed. The analyses, which are based on the entropy and concentration measures, are used to construct tests of independence and measures of association."], ["Some Ancillary Statistics and Their Properties", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["Efficient Bounded-Influence Regression Estimation", "The article concludes with an outline of an algorithm for computing a bounded-influence regression estimator and with an example comparing least squares, robust regression as developed by Huber, and the estimator proposed in this article."], ["The Well-Calibrated Bayesian", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["On the Estimation of the Correlation Coefficient from Grouped Data", "This article proposes two estimators of the correlation coefficient, \u03c1, when statisticians will not construct a master file on individuals because of confidentiality issues. The approach depends on grouping the data according to the values of one of the variables. Group means and total variance for both variables are required to calculate the estimators. The complete bivariate sample need never be compiled. The estimators are shown to be asymptotically normal. Asymptotic and Monte Carlo results are examined. For 1,000 observations in 10 groups, these results indicate that the ratio of the mean squared error (MSE) for one of the proposed estimators relative to that for the usual estimator of \u03c1 ranges from .82 to .95 as \u03c1 ranges from .9 to .25. The proposed estimators are more efficient than previous estimators for grouped data."], ["Maximum Likelihood Estimation of the Survival Functions of Stochastically Ordered Random Variables", "Many times, aspects of populations exist that must satisfy a stochastic ordering requirement. Nevertheless, estimates may not bear out this stochastic ordering because of the inherent variability of the observations. This article will consider the problem of finding maximum likelihood estimates of stochastically ordered survival functions for the cases (a) one survival function being fixed in advance and (b) estimating two survival functions when the data include censored observations. A numerical example is discussed in detail to illustrate the solution to this problem."], [null, null], ["Testing Symmetry", "Tests for symmetry of a distribution function about an unknown value are investigated. The asymptotic distributions under symmetry as well as under near alternatives are given for two kinds of tests: trimmed Wilcoxon tests and tests based on gaps. It turns out that these procedures have a good stability of level under unimodal densities. In a special case (skewness to the left) the efficacies have been calculated. Monte Carlo results are also given."], ["A Test for Asymmetry Associated with the Hodges-Lehmann Estimator", null], [null, null], ["A Simple Predictive Density Function", "An easily computable predictive density is considered. Although involving a plain maximum likelihood technique, it coincides with the posterior predictive density with a noninformative prior. For standard situations achievements are comparable with classical inference."], ["Comment", null], ["Rejoinder", null], ["Testing for Favorable Numbers on a Roulette Wheel", null], ["A Class of Distribution-Free Two-Sample Tests Based on Placements", "We consider a class of two-sample distribution-free tests that are appropriate for situations where one of the sample sizes is large relative to the other. These procedures are based on the placements of the observations in the smaller sample among the ordered observations in the larger sample, and this class of tests generalizes the Mann-Whitney (1947) procedure in much the same way that the class of linear rank tests generalizes the equivalent Wilcoxon (1945) rank sum form. Optimality criteria for choosing a test from this class are discussed and limiting distributions for the associated class of test statistics are determined for the case where only one of the sample sizes goes to infinity."], ["Confidence Limits for Highly Reliable Coherent Systems with Exponentially Distributed Component Life", null], ["Symmetric Matrix Derivatives with Applications", null], ["Book Reviews", null], ["Editorial Board Page", "This article has no abstract"], ["Models for Nonresponse in Sample Surveys", "The literature on the analysis of incomplete data using models is reviewed in the context of nonresponse in sample surveys. The modeling approach provides a large body of methods for handling unit and item nonresponse, some of which cannot be derived from the randomization theory of inference for surveys. Key concepts from the literature on incomplete data, such as factorizations of the likelihood for special data patterns, the EM algorithm for general data patterns, and ignorability of the response mechanism, are discussed within the survey context. Model-based procedures are related to common methods for handling nonresponse in surveys, such as weighting or imputation of means within subclasses of the population."], ["Imputation of Missing Values When the Probability of Response Depends on the Variable Being Imputed", "A method is developed for imputing missing values when the probability of response depends upon the variable being imputed. The missing data problem is viewed as one of parameter estimation in a regression model with stochastic censoring of the dependent variable. The prediction approach to imputation is used to solve this estimation problem. Wages and salaries are imputed to non-respondents in the Current Population Survey and the results are compared to the nonrespondents' IRS wage and salary data. The stochastic censoring approach gives improved results relative to a prediction approach that ignores the response mechanism."], ["The Cost of Drilling for Oil and Gas: An Application of Constrained Robust Regression", "The robust regression method of Huber (1973) is used to fit a model to the cost of drilling for petroleum. Because the model includes a categorical variable (well type), a linear constraint is imposed on the parameter estimates Because the model was fit to the logarithm of cost and because it will be used to make repeated predictions of cost, an adjustment that approximately unbiases the predictions is imposed. The numerical values of the estimates are discussed, and a comparison is made with ordinary least squares."], ["Maximum Likelihood Estimation and Model Selection in Contingency Tables with Missing Data", "In many studies the values of one or more variables are missing for subsets of the original sample. This article focuses on the problem of obtaining maximum likelihood estimates (MLE) for the parameters of log-linear models under this type of incomplete data. The appropriate systems of equations are presented and the expectation-maximization (EM) algorithm (Dempster, Laird, and Rubin 1977) is suggested as one of the possible methods for solving them. The algorithm has certain advantages but other alternatives may be computationally more effective. Tests of fit for log-linear models in the presence of incomplete data are considered. The data from the Protective Services Project for Older Persons (Blenkner, Bloom, and Nielsen 1971; Blenkner, Bloom, and Weber 1974) are used to illustrate the procedures discussed in the article."], ["Estimating Historical Heights", "Historical samples of military, naval, and merchant marine heights suffer from undercounts of short people, undercounts highly irregular compared to the truncated distributions for which standard methods are available. Our knowledge is too imprecise for parametric models of the undercount process but it suffices for intuitive description of the deviations from normality with which estimators should cope. Two new estimators are developed. The first adapts maximum likelihood for truncated normals to height histograms with gradual lower-tail shortfall. The second exploits bends in quantile-quantile plots. Standard error estimates based on Efron's bootstrap appear reliable. The estimators show average heights from British Royal Marine samples much shorter than their American opponents in the Revolutionary War and reveal a statistically significant increase by the 1820's in the British heights."], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["Measurement of Linear Dependence and Feedback between Multiple Time Series", "Measures of linear dependence and feedback for multiple time series are defined. The measure of linear dependence is the sum of the measure of linear feedback from the first series to the second, linear feedback from the second to the first, and instantaneous linear feedback. The measures are nonnegative, and zero only when feedback (causality) of the relevant type is absent. The measures of linear feedback from one series to another can be additively decomposed by frequency. A readily usable theory of inference for all of these measures and their decompositions is described; the computations involved are modest."], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["Lindley's Paradox", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["Qualitative Robustness of Tests", null], ["Bayesian Robustness and the Stein Effect", "In simultaneous estimation of normal means, it is shown that through use of the Stein effect surprisingly large gains of a Bayesian nature can be achieved, at little or no cost, if the prior information is misspecified. This provides a justification, in terms of robustness with respect to mis-specification of the prior, for employing the Stein effect, even when combining a priori independent problems (i.e., problems in which no empirical Bayes effects are obtainable). To study this issue, a class of minimax estimators that closely mimic the conjugate prior Bayes estimators is introduced."], ["The Use of Cross-Section Data to Characterize Macro Functions", "This article investigates the use of individual cross-section data to describe macro functions. Necessary and sufficient conditions (denoted by AS) are found for ordinary least squares (OLS) slope coefficients from a cross section to consistently estimate the first derivatives of the macro function. AS embodies both sets of aggregation assumptions known; linear aggregation and sufficient statistics, and thus represents generalized aggregation conditions. A methodology is given for estimating second-order derivatives of the macro function from cross-section data for distributions of the exponential family, which extends to higher-order derivatives. Finally, a general test of linear aggregation schemes is presented."], ["Estimation of Trigonometric Components in Time Series", "Estimation in time series with an unknown number of deterministic trigonometric components with unknown amplitudes and frequencies is considered. A stepwise procedure is used. At each step the frequency of the largest term in the periodogram of the residual series is used as a starting value for finding the best frequency in the least squares sense. The procedure is stopped when there are no further significant harmonic components, when tested by a multiple-test procedure. The fitting procedure is tried on various time series, including the sun-spot series. For long-term prediction the deterministic model does better for the sunspot series than, for example, autoregressive models."], ["On the Criteria Functions Used for the Estimation of Moving Average Processes", "It is well known that unconditional and conditional least squares estimators are asymptotically maximum likelihood for invertible moving average (MA) processes. By writing the criteria functions for these three estimators in comparable form, we establish simple inequalities between them and also between the corresponding disturbance variance estimates. Further analysis is carried out by examining the expected values of the criteria functions for given (true) coefficients in the MA(1) case. The properties of the expected functions are discussed in relation to the results of other studies of the moving average estimators."], ["Estimation in Survey Sampling: Robustness and Optimality", "It is shown how the criteria of efficiency and robustness can be integrated fruitfully in a single optimality criterion within the framework of the Unified Theory (Godambe 1955). This is achieved by extending the scope of the usual model-based estimation using appropriate sampling designs. Some situations of common occurrence in survey practice are discussed with a numerical study."], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["An Empirical Quantile Function for Linear Models with iid Errors", "The regression quantile statistics of Koenker and Bassett (1978) are employed to construct an estimate of the error quantile function in linear models with iid errors. Some finite sample properties and the asymptotic behavior of the proposed estimator are derived. Comparisons with procedures based on residuals are made. The stackloss data of Brownlee (1965) is reanalyzed to illustrate the technique"], ["A Biweight Approach to the One-Sample Problem", null], ["A Simple Interaction Model for Two-Dimensional Contingency Tables", null], [null, null], ["Confidence Intervals with Jointly Type-II Censored Samples from Two Exponential Distributions", "Strong consistency and asymptotic normality of the maximum likelihood estimators are established in the context of jointly type-II censored samples from two exponential populations. Large-sample confidence intervals are derived for the individual scale parameters as well as their ratio, and some applications to series and parallel systems are discussed. For the ratio of the scale parameters, an exact confidence procedure is developed on the basis of the failure counts in the two samples, and its asymptotic efficiency is investigated."], ["Discriminant Analysis Based on Binary and Continuous Variables", null], ["A General Method for Constructing Simultaneous Confidence Intervals", "A general method is proposed for constructing simultaneous confidence intervals that gives special emphasis to any preselected finite spanning subset in a linear space of estimable functions. The method has a wide range of application, including regression analysis. The length of a confidence interval is determined as the solution to a linear programming problem. The studentized maximum modulus distribution can be used to choose critical values for conservative control of the overall confidence level. The method is compared to Scheff\u00e9's procedure."], ["Simultaneous Inference with Respect to the Best Treatment in Block Designs", "In many practical situations, only inference concerning the unknown best treatment and comparisons of the individual treatments with respect to the best treatment are of primary interest. We give an explicit formulation of this problem in the framework of randomized complete block designs. A procedure based on sample means and two procedures based on signed ranks are proposed. It is seen that, for the problem considered, these procedures have a substantial advantage over what can be deduced from all-pairwise multiple comparisons procedures."], [null, null], ["Detecting Unequal Marginal Scales in a Bivariate Population", "A conditional test is proposed that uses the null hypothesis of bivariate symmetry to detect unequal marginal scales in a bivariate population. The asymptotic normality of the test statistic and the consistency of the test are established. Asymptotic relative efficiency comparisons are made with the standard parametric test in both the bivariate normal case and in a trivariate reduction model case and with two of Sen's (1967) tests in the bivariate normal case. The good performance of the test is also illustrated via a Monte Carlo study."], ["Bayes Procedures for the Classification of Multiple Polynomial Trends with Dependent Residuals", "Three procedures for the classification of multivariate time-dependent data are examined. Two are shown to be Bayes procedures assuming that the time dependence of the data can be described by polynomial regression functions and that the relation among successive residuals is described by a stationary and invertible ARMA process. Relative advantages of these procedures in practical applications and limitations of the model are discussed."], ["Book Reviews", null], ["Editorial Board Page", "This article has no abstract"], ["The Future of Statistics as a Discipline", "The American Statistical Association, enlisting the cooperation of other statistical societies, is seen as the major means of ensuring the future of statistics as a discipline. The ASA must provide the leadership required and represent the discipline to society."], ["Tests for Predictive Relationships between Time Series Variables: A Monte Carlo Investigation", "Bivariate time series models have been used extensively to analyze the relationship between pairs of economic variables. Various tests have been proposed that can be used to examine the adequacy of specific models. The empirical literature is noteworthy for the frequency with which different authors using different tests reach different conclusions, and for the apparent lack of evidence for certain relationships strongly suggested by economic theory. The objective of this study is to use Monte Carlo methods to examine the size and power of alternative tests, and to relate these findings to the analytical structure of the tests."], ["The Identical Distribution Hypothesis for Stock Market Prices\u2014Location- and Scale-Shift Alternatives", "This article explores the identical distribution hypothesis for stock-price changes through a set of optimum non-parametric tests for randomness against location- and scale-shift alternatives. An application of these tests to the daily, weekly, monthly, and quarterly rates of return from 1966 through 1976 for each of the first 15 stocks in the Dow Jones Industrial Average reveals that these series may have constant location parameters throughout the sample period, but the stability of their scale parameters is questionable."], ["A Bayesian Robust Detection of Shift in the Risk Structure of Stock Market Returns", "In this article we provide a statistical procedure for the analysis of stock market prices that is robust toward departures from the normal distribution assumption and that can detect and evaluate a shift of parameters at an unknown time point. The method is an adaptation of a Bayesian inferential procedure developed by Box and Tiao that allows data to deviate moderately from the normal distribution model. It is applied to a set of U.S. stock market prices for 1971\u20131974. In addition to the detection of shift in distribution parameters, the procedure is also applied to the examination of shift of the \u201cbeta coefficients\u201d that represent the degree of undiversifiable (systematic) risk of individual securities. Implications of the empirical findings for financial theories and their applications are sketched."], ["The Rank Version of von Neumann's Ratio Test for Randomness", "Although rank tests for randomness were proposed in the literature as early as 1943, no such test has gained wide acceptance comparable to, say, Spearman's rho test. This may be due to the lack of small-sample theory and of tables of critical values to enable such a test to be carried out on small samples. In this article, we consider the rank version of the von Neumann ratio statistic and we obtain the critical values of this statistic under the randomization hypothesis. In a Monte Carlo experiment we then show that the resulting nonparametric test for randomness has far greater power than the test based on the number of runs up and down. Moreover, under normality, its power vis-a-vis the normal theory von Neumann ratio test is also very good. It is therefore suggested that with the tables presented in this article, the rank von Neumann ratio test for randomness provides an easy and powerful alternative to nonparametric tests now in common use."], ["A Quartile Test for Differences in Distribution", "We propose a simple nonparametric statistic using sample quartiles to test differences in distribution. Simulation results suggest that the test is about equal in power over a wide range of alternatives to the familiar procedure of Kolmogorov and Smirnov. When the two distributions compared differ in both location and dispersion, the quartile test may be more sensitive than the Kolmogorov-Smirnov, Wilcoxon rank-sum, Siegel-Tukey, and runs tests."], ["Graphical Methods for Seasonal Adjustment", "Graphical displays deserve to be a routine part of seasonal adjustment, and their routine use is now feasible because of the current revolution in computer graphical hardware and software. We present and illustrate seven graphical displays that provide powerful tools for judging the adequacy of the seasonal adjustment of a series and for understanding the behavior of the trend, seasonal, and irregular components."], ["An ARIMA-Model-Based Approach to Seasonal Adjustment", "This article proposes a model-based procedure to decompose a time series uniquely into mutually independent additive seasonal, trend, and irregular noise components. The series is assumed to follow the Gaussian ARIMA model. Properties of the procedure are discussed and an actual example is given."], ["Robust Line Estimation with Errors in Both Variables", null], ["Bayes-like Decision Making with Upper and Lower Probabilities", null], ["Survey Design under the Regression Superpopulation Model", "The construction of sample designs and estimators under a linear regression superpopulation model is considered. The anticipated variance, the variance of the predictor computed with respect to the sampling design and the superpopulation model, is used as a criterion for evaluating probability designs and model-unbiased predictors. Regression predictors that are model unbiased and design consistent are constructed."], ["Bayesian Estimation of a Finite Population Total Using Auxiliary Information in the Presence of Nonresponse", "This article presents a Bayesian approach to estimation, in a sample survey setting, of a finite population total for some characteristic of interest when nonresponse is present. A general model is described for situations where a Hansen-Hurwitz sampling plan is used. The model makes use of concomitant information that is related both to the characteristic of interest and to the probability of response. A simple example is included to illustrate the usefulness of the approach."], ["Exploratory Methods for Choosing Power Transformations", null], ["Nonorthogonal Analysis of Variance Using a Generalized Conjugate-Gradient Algorithm", "A method is developed that computes an exact nonorthogonal analysis of variance using cell means. The method is iterative and does not require that the non-orthogonal design matrix be stored or formed. At each stage in the process, a balanced analysis of variance problem must be solved. A monotonicity property for the estimates of the regression sum of squares is derived that could be used to minimize iteration in hypothesis testing. An application of the algorithm to the solution of analysis of covariance problems is also given."], ["Performance of the Durbin-Watson Test and WLS Estimation When the Disturbance Term Includes Serial Dependence in Addition to First-Order Autocorrelation", "Monte Carlo simulation is used to study the power of the Durbin-Watson test and the properties of the corresponding weighted least squares (WLS) estimates when there is serial correlation in the disturbance term, in addition to first-order autocorrelation. The results indicate that the Durbin-Watson test detects first-order autocorrelation, even when other forms of serial dependence are also present. However, routine use of WLS estimation when the Durbin-Watson test is significant may result in inaccurate and inefficient parameter estimates. Therefore, this procedure should be used with caution unless there is a priori knowledge concerning the nature of any serial dependence in the disturbance terms."], [null, null], ["A Confidence Interval for an Exponential Parameter from a Hybrid Life Test", "In life testing, type I and type II censoring may be combined to form a hybrid life test. Epstein (1954) introduced this testing scheme and Epstein (1960b) proposed a two-sided confidence interval to estimate the mean lifetime, 8, of an exponential lifetime following such a test. His conjecture is modified slightly and a proof is given that establishes the validity of the proposed confidence interval."], ["Small-Sample Results for the Kaplan-Meier Estimator", "Whereas much is known about the asymptotic properties of the Kaplan-Meier (1958) estimator (KME) of a survival function, exact results for small samples have been difficult to obtain. In this article, we obtain an exact expression for the \u03b1th moment (\u03b1 > 0) of the KME under a model of proportional hazards. This enables us, under proportional hazards, to (a) study the bias of the KME, and (b) compare the exact variance of the KME to its asymptotic variance."], ["Finite-Sample Properties of Some Old and Some New Estimators of a Common Odds Ratio from Multiple 2 \u00d7 2 Tables", "A simulation study was used to determine the finite-sample properties of various estimators of a common odds ratio from multiple 2 \u00d7 2 tables. The maximum likelihood, Mantel-Haenszel, and Woolf estimators plus four variants of each were considered. The original Woolf estimator and one of its variants are dismissed on the grounds that they often cannot be calculated. In terms of minimum bias, maximum likelihood is the recommended procedure after adding .25 to each cell."], ["Inference for Sichel's Compound Poisson Distribution", null], ["Estimating a Quantile of an Exponential Distribution", null], ["Bivariate Nonparametric Tests for the One-Sample Location Problem", null], ["Simultaneous Confidence Intervals for Ratios of Normal Means", "Given one or more groups of multivariate normal samples, methods are presented for forming simultaneous confidence intervals of all ratios of linear forms of the mean vectors. The methods cover the cases of equal or unequal covariances. In a simultaneous inference context, they are multivariate extensions of a method due to Fieller (1954) for estimation of the ratio of two normal means."], ["Approximations for Distributions of Scan Statistics", "Certain statistical applications deal with the extremal distributions of the number of points in a moving interval or window of fixed length. This article gives an approximation that is highly accurate for several of these distributions. Applications include the maximum cluster of points on a line or circle, multiple coverage by subintervals or subarcs of fixed size, the length of the longest success run in Bernoulli trials, and the generalized birthday problem."], [null, null], ["Multivariate Repeated-Measurement or Growth Curve Models with Multivariate Random-Effects Covariance Structure", "The analysis of multiple-response, repeated-measurement or growth curve models with a multivariate random-effects covariance structure for individuals is considered. Results on estimation, hypothesis testing, and simultaneous confidence bounds for the parameters of the generalized linear model of Potthoff and Roy (1964) are derived for the multiple-response repeated-measurements model under the multivariate random-effects covariance structure. Two numerical examples are presented to illustrate these techniques."], ["Estimating Parameters from Mixed Samples", null], ["Testing of Hypotheses for Distributions in Accelerated Life Tests", "In this paper we consider the problem of inference from accelerated life tests in which a common parametric family of life distributions at the different stress levels is not specified in advance. By assuming a time transformation function, which is a version of the familiar inverse power law, we give a procedure for testing hypotheses that the unknown distributions are specified members of a location-scale family. The behavior of the test procedure is indicated by some simulations. We illustrate the methodology with some real-life data."], ["An Analysis of Transformations Revisited, Rebutted", null], ["Book Reviews", null], ["Preparation of Manuscripts for ASA Journals", null], ["Editorial Board Page", "This article has no abstract"]]}