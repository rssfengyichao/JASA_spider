{"1978": [["Choosing between Logistic Regression and Discriminant Analysis", "Classifying an observation into one of several populations is discriminant analysis, or classification. Relating qualitative variables to other variables through a logistic cdf functional form is logistic regression. Estimators generated for one of these problems are often used in the other. If the populations are normal with identical covariance matrices, discriminant analysis estimators are preferred to logistic regression estimators for the discriminant analysis problem. In most discriminant analysis applications, however, at least one variable is qualitative (ruling out multivariate normality). Under nonnormality, we prefer the logistic regression model with maximum likelihood estimators for solving both problems. In this article we summarize the related arguments, and report on our own supportive empirical studies."], ["A Generalized Compound Poisson Model for Consumer Purchase Panel Data Analysis", "A compound Poisson distribution, the Ehrenberg NBD model, has proven useful in the past for analyzing consumer purchase behavior encountered in dealing with frequently purchased low-cost consumer items. The present article proposes the use of a generalized negative binomial distribution in which the NBD model is used as a purchase occasion component and is combined explicitly with the conditional distributions of the single-purchase volume variables associated with the purchase occasions. Conventional and logit regression methods are illustrated for estimating parameters of the single-purchase quantity probability function. This kind of formulation can be useful for conditional trend analyses and similar segmentation studies."], ["The Bias Problem in Smear-and-Sweep Analysis", "The usefulness of the smear-and-sweep technique as developed in The National Halothane Study is questioned because of greater-than-expected bias. The Halothane study took into account the bias inherent in smear-and-sweep, and an example was given to suggest that any remaining bias could be eliminated by an extension of the technique. However, a close reexamination of the example shows that a high degree of bias may remain. Another example is given to show that the bias does not necessarily decrease as the smear-and-sweep index is improved. Imperfection in the index variable, a contributing factor to bias, is shown to be inherent in smear-and-sweep. A set of restrictive conditions are given under which smear-and-sweep may be an appropriate technique."], ["Small-Sample Properties of Simultaneous Equation Estimators with Multicollinearity", "A Monte Carlo simulation is employed to reinvestigate the general disagreement in the literature regarding the small-sample properties of simultaneous equation estimators under widely different levels of multicollinearity. This disagreement has been attributed to the greater use by more complex estimators of information on variables excluded from each equation, producing the advantage in inference of increasing precision at low levels of collinearity, but the disadvantage of greater estimator sensitivity with higher collinearity. Although simulation results indicate improvement of some less complex techniques relative to their more complex counterparts as collinearity rises, extreme collinearity is required to generate substantial reversals in relative performance."], ["A Simple Method of Multiple Comparisons of Means", null], ["Estimating Mixtures of Normal Distributions and Switching Regressions", "Since the likelihood function corresponding to finite mixtures of normal distributions is unbounded, maximum likelihood estimation may break down in practice. The article introduces the \u201cmoment generating function estimator\u201d defined as the estimator which minimizes the sum of squares of differences between the theoretical and sample moment generating functions. The consistency and asymptotic normality of the estimator are proved and its finite sample behavior is compared to that of the standard method of moments estimator by Monte Carlo experiments. The estimator is applied to the Hamermesh model of wage bargain determination."], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["Combining Independent Chi-Squared Tests", null], ["Tail Probabilities for Contingency Tables with Small Expectations", null], ["The Multivariate Normal Mean with Intraclass Correlated Components: Estimation of Urban Fire Alarm Probabilities", null], ["Optimal Selection from a Random Sequence with Learning of the Underlying Distribution", "Consideration is given to an extension of the so-called secretary problem in which each alternative has an observable value drawn from a distribution unknown a priori. A uniform distribution is considered here, because this gives analytical solutions which are easily compared with previous work. It is shown that when maximizing the probability of selecting the best candidate, learning does not contribute to the solution. When maximizing expected value, learning does play a role, giving a solution intermediate between that based on ranks and that based on known distributions."], ["Canonical Analysis: A Factor-Analytic Method of Comparing Finite Discrete Distribution Functions", "The methods of factor analysis are adapted to the comparison of finite discrete distribution functions. Each element of a finite class of distribution functions is presented in a canonical form in which components differentiating and uniting the functions are easily distinguished and are readily calculated using factor-analysis algorithms. This technique, which we call canonical analysis, has uses in heterogeneity and goodness-of-fit analysis and in the classification of distribution functions."], ["A Scale-Free Goodness-of-Fit Test for the Exponential Distribution Based on the Lorenz Curve", "The sample Lorenz curve provides a powerful, easily computed goodness-of-fit test for exponentiality which does not depend on the unknown scale parameter. Exact critical values and asymptotic results are given, which can also be used to test the related hypothesis of randomness on an interval. General limit theorems show that the sample Lorenz curve converges almost surely to the population Lorenz curve and that the standardized Lorenz statistic converges to normality provided the underlying random variable has finite variance. Asymptotic relative efficiencies and Monte Carlo power estimates are also given."], ["The Logistic Model and Estimation of Latent Structure", "Consider the logistic model for dichotomous response involving a group of individuals with varying levels of ability and a set of items with varying degrees of difficulty. This article is concerned with estimating the parameters of the latent ability distribution for any given group of individuals. An iterative procedure for obtaining maximum likelihood estimates of these parameters based on the missing information principle is presented and illustrated with real data. The article also contains results on asymptotic variances and covariances of estimators and a discussion of the use of ability distributions in comparing groups of individuals."], ["A Class of Alternatives to Independence in Contingency Tables", "A class of alternative hypotheses to independence is proposed for two-way contingency tables. It is assumed that a certain proportion of the cell probabilities under independence has been removed from (or put into) each of a subset of cells and redistributed over (or taken from) the remaining cells, keeping the marginals unchanged. The redistribution or depletion is not necessarily restricted to neighboring cells. The proposed alternatives can be expressed in log-linear form amenable to usual methods of analyses. Two numerical examples are given. Some generalizations for two-way and multi-way tables are discussed."], ["Nonparametric Maximum Likelihood Estimation of a Mixing Distribution", "The nonparametric maximum likelihood estimate of a mixing distribution is shown to be self-consistent, a property which characterizes the nonparametric maximum likelihood estimate of a distribution function in incomplete data problems. Under various conditions the estimate is a step function, with a finite number of steps. Its computation is illustrated with a small example."], [null, null], ["An Exact Test for the Presence of Random Walk Coefficients in a Linear Regression Model", null], ["Normal Discrimination with Unclassified Observations", "Fisher's linear discriminant rule may be estimated by maximum likelihood estimation using unclassified observations. It is shown that the ratio of the relevant information contained in unclassified observations to that in classified observations varies from approximately one-fifth to two-thirds for the statistically interesting range of separation of the populations. Thus, more information may be obtained from large numbers of inexpensive unclassified observations than from a small classified sample. Also, all available unclassified and classified data should be used for estimating Fisher's linear discriminant rule."], ["An Index of Agreement between a Hypothesized Partial Order and an Empirical Rank Order", null], ["Treatment Contrasts in Paired Comparisons: Large-Sample Results, Applications, and Some Optimal Designs", "Treatment contrasts in paired comparison experiments are considered. Given that specified orthonormal treatment contrasts are null, remaining treatment parameters, orthonormal contrasts among them, and their logarithms are estimated. The estimators are shown to be consistent and, when suitably scaled and centered, to have distribution functions that are normal in the limit for large sample sizes. Hypothesis tests on treatment contrasts are obtained. The limiting distribution functions of related likelihood ratio tests are derived for defined local alternatives and their noncentrality parameters are shown. The theoretical results are applied to experiments with factorial treatment combinations and some optimal design results are obtained."], ["The Randomized Play-the-Winner Rule in Medical Trials", "In a sequential medical trial, a simple randomized treatment assignment rule is proposed and analyzed. On the average this rule assigns more patients to the better treatment, and it is applicable to the case where patients have delayed responses to treatments. This new assignment rule is studied for both a fixed sample size and an inverse stopping rule."], ["On Construction of Four-Dimensional Incomplete Block Designs", null], [null, null], ["Nonnegative and Preliminary Test Estimators of Variance Components", "Nonnegative estimators of variance components involving preliminary tests are studied. The restricted maximum likelihood estimator and other truncated estimators may be viewed as preliminary test estimators. A new preliminary test estimator is proposed and studied. Recommendations of the levels of preliminary tests are made."], ["Simple BAN Estimators of Correlations for Certain Multivariate Normal Models with Known Variances", "It is well-known that in certain multivariate normal models with known variances, maximum likelihood estimation of correlations is arithmetically cumbersome. For certain of these models, a relatively simple estimation technique based on the sufficient statistics is given and shown to be best asymptotically normal. The procedure uses the fact that many of the likelihood equations for these models are essentially cubic equations. A consistent, explicit solution for the associated cubic likelihood equation is found and shown to have the appropriate efficiency and normality properties. Considered in detail are the intraclass, autoregressive, and moving average models."], ["The Prediction Information in the Latest Failure", "When a system consisting of many independently functioning components of the same type is put into service, some action may be appropriate as soon as some proportion of the components has failed. It is, therefore, useful to be able to predict later failure times from earlier ones. We compare the information in the latest available failure time to that contained in all previous failures, for predicting later failures. For many of the well-known failure distributions commonly used to model component life, the relative amount of prediction information in the latest available failure time is surprisingly high."], ["Improving the Limited Information Maximum Likelihood Estimator When the Disturbances are Small", "The limited information maximum likelihood (LIML) estimator is shown to be inadmissible in terms of asymptotic expansions of the distributions of the estimators. The LIML estimator is improved by combining it linearly with the two-stage or the ordinary least squares estimator."], ["Modification of the Kolmogorov-Smirnov Statistic for Use with Correlated Data", "The one-sample Kolmogorov-Smirnov goodness-of-fit test (K-S test) is designed for use with independent data. Critical values of the K-S statistic can be highly sensitive to correlated data. For data representing sampling of a second-order autoregressive process, an empirically derived correction for the K-S statistic provides correct critical values as well as increased power. The correction is a simple linear function of a parameter \u03c4 which is derived from the second and the fourth moments of the normalized spectrum of the autoregressive process."], [null, null], [null, null], ["Book Reviews", null], ["Corrigenda", null], ["Editorial Board Page", "This article has no abstract"], ["The Effect of Air Pollution upon Mortality: A Consideration of Distributed Lag Models", "The relationship between daily mortality and urban air pollution is considered in a regression context. Several distributed lag models are examined in order to discover a possible delayed mortality response. The results of those models with geometrically declining lag coefficients are consistent with those of the other lag models. Adjustment is made for serial correlation, and the consequences of measurement error are explored. Application of the various models to four to six different time periods allows an examination of the consistency of these models. Results for all time periods indicate associations between daily mortality and air pollution values. The distributed lag models suggest that any lagged effect is negligible in comparison with the immediate response."], ["Comment", null], ["The Use of Monetary Incentives in National Assessment Household Surveys", "The National Assessment of Educational Progress household survey of young adults 26\u201335 years old uses a unique monetary incentive procedure to effectively reduce nonresponse and to increase overall cost effectiveness. As a result of poor response in the first year of National Assessment, a special followup study was conducted to examine alternative field procedures; four different incentive plans were tested in a designed experiment imposed on 64 area segment sampling units. The results of the experimental study and of the adopted monetary incentive procedure on response rates in Years 2, 3, 4, and 5 of the National Assessment household surveys are reported."], ["Power Differences between Pairwise Multiple Comparisons", null], ["Comment", null], ["Rejoinder", null], ["A Monte Carlo Investigation of the Box\u2014Cox Transformation in Small Samples", null], ["Percentile Regression: A Parametric Approach", "For situations in which no assumptions are explicitly made about error distributions, other model assumptions may imply constraints on the form of the residual distribution. This is true of regression models which assume that percentiles are functions of the regressor variable. Hogg (1975) used a procedure based on signs of residuals to fit linear percentile models. Advantages of making (and testing!) explicit parametric assumptions in this context are illustrated using a linear model for scale and location with normal errors. This is applied to the data on professors' salaries discussed by Hogg."], ["Optimization of Earnings in Stochastic Industries, with Applications to Casinos", "Gambling casinos and banks are examples of stochastic industries whose sole commodity is cash. To optimize income, cash reserves should be determined so that earnings, subject to default penalties, are a maximum. This article provides a straightforward procedure, involving a financial growth equation, that can readily be applied to any cash-transactional business to obtain cash reserve requirements for various default criteria. Examples involving actual cash flow data from two Las Vegas casinos are given and analyzed to confirm the felicity of the method."], ["Pseudorandom Number Assignment in Statistically Designed Simulation and Distribution Sampling Experiments", "This research investigates various strategies for assigning pseudorandom numbers to experimental points in statistically designed simulation and distribution sampling experiments. Strategies studied include the widely advocated practices of (i) employing a common set of pseudorandom numbers for all experimental points, and (ii) assigning a unique set of pseudorandom numbers to each experimental point. An alternative, based upon blocking concepts in designed experiments, is devised and shown to improve upon existing recommendations for a wide class of problems. A small simulation, a pilot study of a hospital resource allocation problem, illustrates the new strategy."], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["Qualitative Controlled Feedback for Forming Group Judgments and Making Decisions", "We present a new methodology for helping members of a group arrive at carefully reasoned value judgments or decisions. The new procedure, called qualitative controlled feedback, presents each group member with a common question; each member is asked independently for both an answer to the question and for reasons which he feels justify his answer. An intermediary collects all stated reasons and informs all group members of the composite of reasons (but not of the answers). The question is presented to the group members independently again, and the process is repeated until the individual judgments stabilize."], [null, null], ["Efficacies of Measures of Association for Ordinal Contingency Tables", null], ["A Decision-Theoretic Approach to the Aggregation Problem at the Pre-Data-Collection Stage", "We present a decision-theoretic approach to finding optimal aggregation schemes when the aggregation is made at the pre-data-collection stage. A criterion is presented for the optimal aggregation of variables, its properties are analyzed, and it is compared with other criteria in the literature for good aggregation. In the course of determining this criterion, we derive endogenously the disaggregation procedure by which inferences about disaggregated data are made from aggregated data. It is shown that our analysis can be used to determine optimal aggregation schemes in input-output analysis. We apply our model, as an example, to data from the Netherlands."], ["An Application of an Urn Model to the Design of Sequential Controlled Clinical Trials", null], ["Generalized Linear and Quadratic Discriminant Functions Using Robust Estimates", null], ["Sample Size Determination in Bayesian Discriminant Analysis", "The preposterior analysis of the two-population classification problem for multivariate normal densities with equal covariance matrices is presented. Consideration is given to the case that arises when the common precision matrix is known and the mean vectors have normal prior densities, and to the case that arises when the precision is unknown and the prior densities are normal-Wishart. The expression for the preposterior expected loss is used to find the expected value of sample information and hence the optimal sample size."], ["Bayesian Analysis of the Linear Model Subject to Linear Inequality Constraints", "This article considers the general linear model when the parameter space is subject to linear inequality constraints. A Bayesian analysis of this model is presented using a natural conjugate prior of the mixed type. Expressions are given for the probability that constraints are binding and for the distribution of the parameters. When prior information about the parameters is vague, the Bayesian and sampling methods of model selection are compared. The techniques are applied to a time series of temperatures of a chemical reaction."], ["Regression Selection Strategies and Revealed Priors", "The computation and selection of constrained regressions may be motivated by prior information and, if so, a regression selection strategy reveals the implicit prior. The selection strategies of principal component regression, stepwise regression, and imposing equality constraints are connected with prior densities which are uniform on spheres, hyperbolas, and cones, respectively. Omitting variables in a predetermined order reveals lexicographic priors."], ["Dorfman-Type Group Testing for a Modified Binomial Model", "In this article we introduce a new group-testing model which we refer to as the modified binomial model. This new model, when applicable, not only requires a smaller per unit expected number of tests to identify all units (in a population of dichotomous units) than does the frequently considered binomial model, but also is always preferable to individual testing. We consider optimal Dorfman-type procedures under the modified model and present methods for determining the best choices of group sizes for both finite and infinite population cases. We also offer some new results for the binomial model."], ["Do Stronger Players Win More Knockout Tournaments?", null], ["The Bayes Sequential Procedure for Estimating the Arrival Rate of a Poisson Process", null], ["Some Angular-Linear Distributions and Related Regression Models", "Parametric models are proposed for the joint distribution of bivariate random variables when one variable is directional and one is scalar. These distributions are developed on the basis of the maximum entropy principle and by the specification of the marginal distributions. The properties of these distributions and the statistical analysis of regression models based on these distributions are explored. One model is extended to several variables in a form that justifies the use of least squares for estimation of parameters, conditional on the observed angles."], ["Some Two-Level Multiple-Response Factorial Plans", null], ["A New Procedure for Selecting a Subset Containing the Best Normal Population", null], ["Asymptotic Theory of Least Absolute Error Regression", null], ["Minimax Adaptive Generalized Ridge Regression Estimators", "We consider the problem of estimating the vector of regression coefficients of a linear model using generalized ridge regression estimators where the ridge constant is chosen on the basis of the data. For general quadratic loss we produce such estimators whose risk function dominates that of the least squares procedure provided the number of regressors is at least three. We study the problem by the usual reduction to estimating the mean vector of a multivariate normal distribution. Our results on minimax estimation in this context are of independent interest."], ["Weighted Rank Statistics for Simple Linear Regression", "This article is concerned with statistical inferences for the slope parameter \u03b2 in the simple linear regression model. Rank procedures are proposed which extend the procedures of Theil and Sen by using weights for the pairwise slopes. Estimation, confidence interval, and hypothesis testing problems are considered."], ["Exact Confidence Intervals for Linear Combinations of Variance Components in Nested Classifications", "Methodology is proposed for the construction of exact confidence intervals on nonnegative linear combinations of variance components from nested classification models. Examples are given for the one-fold and two-fold classifications. The robustness of these confidence intervals to model breakdown is also discussed."], ["Estimating Strictly Increasing Regression Functions", "The maximum likelihood estimate of a nondecreasing regression function with independent, normal errors has been studied in detail in the literature. However, it is often constant over one or more intervals and for this reason may be unacceptable if the regression function is believed to be strictly increasing. Using simulation techniques, the least squares line, the maximum likelihood estimate, and a weighted average of these two are compared here. In each case considered, the weighted average is strictly increasing with probability near one and has smaller total mean squared error than the maximum likelihood estimator."], ["A Bivariate Test for the Detection of a Systematic Change in Mean", null], ["An Extension of Colton's Model for Comparing Two Medical Treatments", "In this article the Colton fixed sample size model for choosing the better of two treatments is extended by including those patients who did not participate in the experiment prior to deciding which treatment is superior. The optimum Bayesian solutions are found for normal observations and comparisons are made between them and the corresponding results based on Colton's model. Considerably different results are generally obtained by the proposed model as compared to Colton's model in terms of both sample size and risk."], ["Inferences for the Two-Parameter Exponential Distribution under Type I Censored Sampling", "Inferences concerning the location and scale parameters of an exponential distribution are discussed for samples censored at a fixed value. The procedures considered are uniformly most powerful unbiased if the tests are performed with replacement and they seem to be quite reasonable when testing without replacement."], ["Tables of the Studentized Augmented Range and Applications to Problems of Multiple Comparison", null], ["Estimating Means When a Group of Observations is Classified by a Linear Discriminant Function", "Suppose that a group of observations is known to have come from either one of two normal populations with unknown means and common variance. After the group is classified by the linear discriminant function, it is pooled with the sample from the population to which it belongs to estimate the unknown mean. Weighted estimators of the population means are defined. The biases and mean squared errors of the estimators in the univariate case are obtained. Estimators of the population means using the estimated weighting constant are proposed, and the relative efficiencies of the estimators are studied."], ["A Small-Sample Comparison of Rank Score Tests for Parallelism of Several Regression Lines", null], ["On Approximations for the Central and Noncentral Distribution of the Generalized Variance", "It is shown how the noncentral probability density function of the generalized variance can be approximated by a central probability density function under certain conditions by using moments and moment generating functions. It is also shown that these density functions can be approximated by a linear function of two gamma densities, which can readily be applied to practical problems. The theoretical results are verified by a sampling experiment."], ["Book Reviews", null], ["Corrigenda", null], ["Editorial Board Page", "This article has no abstract"], ["Small-Sample Comparisons of Exact Levels for Chi-Squared Goodness-of-Fit Statistics", null], ["Seasonality in Regression: An Application of Smoothness Priors", "This article argues that conventional approaches to the treatment of seasonality in econometric investigation are often inappropriate. A more appropriate technique is to allow all regression coefficients to vary with the season, but to constrain them to do so in a smooth fashion. A Bayesian method of estimating smoothly varying seasonal coefficients is developed, based on Shiller's (1973) approach to estimating distributed lags. In a sampling experiment, this technique outperforms ordinary least squares by a substantial margin. An application of this technique to the estimation of the demand for soft drinks is also presented."], [null, null], ["The Use of the Box-Cox Transformation in Limited Dependent Variable Models", "The general limited dependent variable model discussed in this article permits skewness in a pretruncated variable by transforming it within the class of Box-Cox transformations. As a by-product this general model also provides a convenient nesting framework for statistically distinguishing between numerous limited dependent variable models. An application to a model of the supply of bilateral foreign aid illustrates the ability of the general model to empirically distinguish between competing specifications."], ["Estimating Household Income from Location", "A Block Income Estimating Procedure (BIEP) in presented for estimating the average income of the households of a Census block, using block housing information and Census tract distributions relating to housing and household income. Such block income estimates are very useful when dealing with household data sets which do not include income but where the household's address is known. In addition, BIEP can be used to estimate the average income of geographic areas that do not coincide with Census tracts or postal zip code areas, the smallest spatial units for which official data are available. BIEP's efficacy is tested using a special Census tabulation for Philadelphia school feeder areas, and it is compared with its closest rival, a tracts-average procedure. BIEP is found to work well relative to the other procedure."], ["Forecasting with Limited Information: ARIMA Models of the Trailer on Flatcar Transportation Market", "This paper evaluates the appropriateness of autoregressive integrated moving average (ARIMA) time-series models for forecasting in information-scarce environments. Such environments are defined and a specific transportation sector example examined. It is shown that ARIMA models adequately characterize economic activity in this example. ARIMA model forecasts are seen to dominate alternative models, and to provide information required for market efficiency. Specific attention is focused on a procedure for isolating potential model misspecification and on the need for post-sample forecast quality analysis."], ["Optimum Cluster Designs within a Primary Unit Using Combined Telephone Screening and Face-to-Face Interviewing", "Telephone samples are widely used for screening to locate special subgroups in the population where the final interview will be conducted face to face. This article discusses the conditions when this method is more efficient than face-to-face screening. An analysis of cost functions indicates that the phone methods will be more efficient unless the homogeneity within the cluster is small, the density of interviews is low, and/or the locating and screening costs are low relative to the cost of the interview."], ["On the Performance of Some Multinomial Classification Rules", "This article presents and discusses a new multinomial classification procedure based on a discrete distributional distance. Its performance along with other commonly used classification procedures is assessed through Monte Carlo sampling experiments under different population structures. In addition to reporting results consistent with the work of Gilbert (1968) and Moore (1973), the article describes sampling experiments which show that the new distance procedure is generally superior, in terms of both the mean actual and mean apparent errors, to the usual full multinomial rule in situations of disproportionate sample sizes."], ["Possible Increases in the Underreporting of Cigarette Consumption", "Data from four major surveys, spanning the years since the Surgeon General's Report, suggest a significant reduction in rates of cigarette smoking. These data, however, conflict with production and sales data which record only a slight reduction. Explanations for this discrepancy range from problems in the surveys' methodology to increased underreporting of cigarette consumption because of both a growing awareness of the threat to health and the social undesirability of smoking. This article emphasizes the need for caution in the design of surveys and interpretation of their results, regardless of the explanation of the discrepancy."], ["Consistent Regression Methods for Discriminant Analysis with Incomplete Data", "Modifications are proposed for a method of discriminant analysis with missing values described by Chan, Gilman, and Dunn (1976). The modified methods are special cases of techniques for handling missing values in multivariate linear regression. Less stringent conditions for when missing values are missing at random are suggested."], ["A Survillance System for Congenital Malformations", "A surveillance system for congenital malformations in single and multiple hospitals is described. The system is comparable to the cusum technique with regard to the period in which data calling for alarm are gathered, but involves shorter periods of time for data processing. The required calculations are simple and thus can be carried out by the local staff of a hospital."], ["Sequential Medical Trials for Comparing an Experimental with a Standard Treatment", "The Bayes sequential solution for a particular formulation of the problem of comparing an experimental with a standard treatment in the context of medical trials is determined. For large horizon size, this solution is represented as the solution of a free-boundary problem which also arises as the solution of a related Wiener-process problem. The nature of the solution of this related problem and the approximation to the medical-trials problem provided by this related problem are examined. Suboptimal procedures are evaluated and one of these, a Wald-type sequential procedure, is found to be surprisingly efficient."], ["Modified Two-Armed Bandit Strategies for Certain Clinical Trials", "A procedure which maximizes the expected number of successes in a clinical trial involving two treatments can usually be found only by backward induction. Not only is it difficult to find an optimal procedure but, once found, it is difficult to describe and cumbersome to communicate. A procedure is suggested which depends on the information present concerning the treatments. This procedure is easy to calculate and approximates an optimal procedure quite well. It is applicable to trials for which the number of patients is unknown as well as those of known duration."], ["Statistical Diagnosis and Tests of Factor Hypotheses", "Certain symptoms are of diagnostic value because they reflect the progress of a multistage disease. To analyze such cases, a dynamic symptom/disease model is constructed. The model is seen to be consistent with observations about skewed, dependent symptom distributions for certain diseases. The uniformly most powerful unbiased test of hypotheses about the disease factor leads to a linear discriminant function. Prior knowledge of the symptom/factor relationship can be used to correct the procedure for nuisance effects or lacking such information, the model can be structured so that the test is independent of the nuisance factors."], ["Variance Estimation in Finite Population Sampling", "Under a linear regression model, the best linear unbiased estimator (BLUE) for a finite population total can be obtained. The problem studied here is that of estimating the variance for setting large-sample confidence intervals about the BLUE when the model generating this estimate is inaccurate. A robust variance estimator is derived, and its asymptotic properties are shown to compare favorably with those of the weighted least-squares variance estimator. The robust variance estimator is shown to be asymptotically equivalent to the jackknife variance estimator under rather general conditions. These are extensions of results previously established for the ratio estimator by Royall and Eberhardt (1975)."], ["Finite Population Sampling and Robust Estimation", "The work of Royall and Herson (1973a, 1973b), ensuring the robustness of the standard ratio estimator against polynomial superpopulation models by choosing balanced samples, is extended to a more general regression estimator. The requirement for robustness is then a relationship between the moments of the sample units and those of the remainder of the population which may be achieved approximately by unequal probability sampling."], ["Sample Size Selection in Regression Analysis When there is Nonresponse", null], ["Estimation in Some Nonlinear Models", "Extensions of linear model contrasts to general and location-scale models are proposed. These extensions are defined in terms of shift functions which measure how much the variables from one population must be shifted to be aligned in distribution with the variables from another. A general estimate based on empirical distribution functions and three estimates appropriate for the location-scale model are considered and compared in terms of asymptotic relative efficiencies. An estimate based on trimmed means and standard deviations turns out to have nice robustness properties in the location-scale model."], ["Repeated Measurements on Autoregressive Processes", "Estimation of parameters and tests of hypotheses are studied in first-order autoregressive processes where the process is observed several times over a given time interval. The process may be homogeneous (i.e., the parameters may be constant over time) or inhomogeneous (time-varying parameters). Sufficient statistics under normality are obtained for various cases and several tests of hypotheses are given."], ["Discriminant Analysis Based on Ranks", "A model-free rank procedure is proposed for the two-population discrimination problem that enables the practitioner to better control the balance between the two probabilities of misclassification. The method is applied to the discriminant functions resulting from normal assumptions and also to an adaptive one which is a weighted average of the linear and quadratic discriminant functions, where the weights are determined from the data. A Monte Carlo study shows that the rank method can greatly improve the balance between the two misclassification probabilities while keeping their average comparatively small."], [null, null], ["A Note on the Geisser-Greenhouse Correction for Incomplete Data Split-Plot Analysis", null], ["Complete-Link Cluster Analysis by Graph Coloring", null], ["Sequential Estimation of a Truncation Parameter", "Consider the problem of sequentially estimating the parameter \u03b8 of a uniform distribution on (0, \u03b8). It is shown that if the loss is measured by squared error plus a linear cost function, and the prior on \u03b8 is given by a Pareto distribution, a simple heuristic procedure incurs an excess risk above the Bayes risk not greater than the cost of three observations. The result is extended to a wider class of distributions which includes the uniform and to a wide class of priors."], ["Sequential Confidence Intervals for the Mean of a Subpopulation of a Finite Population", "Sequential confidence intervals for the parameters of a subpopulation of a finite population are studied. Procedures are suggested using the mean, median, and trimmed means; these procedures are shown to be more efficient than their counterparts which are based on independent, identically distributed observations from infinite populations. The major technique used is to \u201clinearize\u201d the estimates, yielding as a simple consequence proofs of central limit theorems. A Monte Carlo study shows that the small-sample performance is very good."], ["A Comparison of Two Tests for the Significance of a Mean Vector", null], ["A Robust Test for Dispersion", "The simplicity and surprisingly good small-sample power properties of the ordinary sign test motivate its use, in suitably adapted form, as a dispersion test. The proposed test statistic is based on the number of observations lying more than a specified distance from the sample mean. For symmetric and moderately skewed distributions, the proposed test is robust and has good power properties."], ["The Exact Distribution of Bartlett's Test Statistic for Homogeneity of Variances with Unequal Sample Sizes", null], ["Distribution-Free Tests for Ordered Alternatives in a Randomized Block Design", "In this article we consider a class of test statistics that are useful for testing against ordered alternatives in balanced or unbalanced block designs. The approach consists of forming a statistic on each block and then combining the block statistics as a weighted sum to obtain one overall test statistic. Large-sample properties such as asymptotic normality and asymptotic relative efficiency as the number of blocks tends to infinity are considered. Throughout the article special attention is given to a Jonckheere-type statistic. Some consideration is given to the selection of the optimal weighting constants for the Jonckheere statistic."], ["On Pairwise and Mutual Independence: Characterizations of Rectangular Distributions", null], ["Book Reviews", null], ["Corrigenda", null], ["Editorial Board Page", "This article has no abstract"], ["Chance, Statistics, and Statisticians", null], ["Small-Area Estimation with Application to Unemployment and Housing Estimates", "The purpose of this study is to investigate methodologies for constructing intercensal estimates of various characteristics of the population for small areas. The proposed methodology is illustrated mainly in the context of unemployment estimates, with one section utilizing dilapidated housing estimates. Alternative synthetic estimates of unemployment based on the 1970 Census 20-percent sample are investigated and their relative error is analyzed. The reliability of the synthetic estimates is discussed in the context of dilapidated housing estimates. Two types of regression models are studied, and the improvements obtained by excluding outliers from the regression are discussed."], ["An Interviewer Variance Study for the Eight Impact Cities of the National Crime Survey Cities Sample", "A report is provided on an investigation of the variability of the National Crime Survey (NCS) statistics attributable to interviewers. Interpenetrated assignment patterns were used to estimate the effects of interviewers on data from the eight impact cities of the NCS cities sample. Such a design permitted estimation of the interviewers' contributions to the correlated component of response variance for a selected group of items for each impact city. The effects of NCS interviewers on the survey statistics varied among the cities and according to the nature of the statistics."], ["Multivariate and Multipurpose Stratification", null], ["Randomized Response Technique in a National Survey", "The randomized response technique was used in the 1973 National Survey of Family Growth to produce estimates of the number of women having abortions during a 12-month period in the conterminous United States. The model applied used two unrelated questions in separate half-samples, with a coin as the randomizing device. While the technique resulted in a higher estimate for the number of women with abortions than has previously been obtained through direct questions or reporting systems, it also yielded divergent estimates of abortion from the two half-samples. Possible causes for this divergence are discussed."], ["Sampling Methods for Random Digit Dialing", "A method of sample selection for household telephone interviewing via random digit dialing is developed which significantly reduces the cost of such surveys as compared to dialing numbers completely at random. The sampling is carried out through a two-stage design and has the unusual feature that although all units have the same probability of selection, it is not necessary to know the probabilities of selection of the first-stage or the second-stage units. Simple random sampling of possible telephone numbers, within existing telephone exchanges, is inefficient because only about 20 percent of these numbers are actually telephone numbers assigned to households. The method of selection proposed reduces the proportion of unused numbers sharply."], ["A Comparison of the Modified-Tukey and Scheff\u00e9 Methods of Multiple Comparisons for Pairwise Contrasts", "The Kramer (1956), Spj\u00f8tvoll and Stoline (1975), Hochberg (1976), and Games and Howell (1976) modified forms of the Tukey test are compared with the Scheff\u00e9 (1959) test for (1) rates of Type I error and (2) sensitivity to varying degrees of sample-size imbalance and variance heterogeneity when sampling from normal and skewed distributions. Only the Hochberg (1976) and Games and Howell (1976) procedures control their rates of Type I error at or below the nominal five percent level for all conditions investigated; however, the Games and Howell (1976) procedure is more powerful and always results in Type I error values which are closer to the level of significance."], ["Optimum Subsample Sizes for the Bartlett-Kendall Homogeneity of Variance Test", null], ["Evolution Times of Languages", "A problem in anthropological linguistics is to reconstruct, from present-day linguistic data, a family tree depicting the ancestry of a family of languages. There are two parts to the problem. The first is to construct the family tree showing the sequence of language separations; this is analogous to classifying biological species by degree of similarity. The second is to estimate when the separations occurred. In this article, a stochastic model is given for the process of language change. Then a statistical procedure is developed for estimating the separation times and characterizing the rates of word replacement."], ["A Review of the Manuals for BMDP and SPSS", "SPSS and BMDP have much in common, but they have contrasting emphases. The SPSS manual is intended for an unsophisticated audience. It has low-level statistical explanations and carefully written directions for running the programs, but not much about computational procedures. In contrast, the BMDP manual is more sophisticated, with not much statistical explanation, brief explanation of the control language, and substantial discussion of algorithms. We summarize our review with a listing of qualities which we consider important in a manual and our ratings for SPSS and BMDP."], ["A Review of the Manuals for BMDP and SPSS", "Objectives for the review of a user guide of a statistical computing package are presented. Sixteen major categories are used to compare the capabilities described in the BMDP and SPSS guides. This is followed by additional specific comments on each package and its guide. It is hoped this review will stimulate interest in developing standards for user guides, in reviewing such guides, in evaluating statistical computing capabilities, and in improving these capabilities. It is also hoped this paper will contribute to the understanding of these two fine statistical packages."], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["Rejoinder", null], ["Regression Estimation after Correcting for Attenuation", "The limiting distribution of the regression coefficients calculated from a correlation matrix that has been corrected for attenuation is obtained. Methods of estimating the covariance matrix of the vector of regression coefficients are presented. Nonnormal regression variables and nondiagonal error matrices are considered. The procedures are illustrated with data on the socioeconomic career."], ["Methods of Analysis of Linear Models with Unbalanced Data", null], ["Regression and ANOVA with Zero-One Data: Measures of Residual Variation", "We consider regression situations for which the response variable is dichotomous. The most common analysis fits successively richer linear logistic models and measures the residual variation from the model by minus twice the maximized log likelihood. General measures of residual variation are considered here, including ordinary squared error and prediction error as well as the log likelihood. All of these are shown to be satisfactory in a certain primitive sense, unlike quantitative regression theory where only squared error is logically satisfactory. The relation of Goodman and Kruskal's measures of categorical association to the theory of penalty functions and probability elicitation is demonstrated."], [null, null], ["Size and Power Assessments of Tests of Hypotheses on Survival Parameters", "Assuming the time-dependent component of Cox's form of the hazard function to be specified by the constant, Weibull, and Gompertz, produces three failure density models. Using simulation techniques, size and power comparisons between tests of hypotheses (concerning the regression parameters) arising from Cox's nonparametric method and tests arising from the three parametric models are made. The test statistics arise from the likelihood ratio criterion and the asymptotic normality property of maximum likelihood estimators."], ["Selection of Trimming Proportions for Robust Adaptive Trimmed Means", "Asymptotic variances of trimmed means for a family of symmetric distributions including the uniform, normal, and double exponential are examined and used to suggest forms of adaptive trimmed means as robust estimators of location. The proportions of trimming in the adaptive estimators are based on simple functions of easily obtained measures of nonnormality."], ["Estimation of Variance Components Using Residuals", "We consider the estimation of variance components in a general analysis of variance model by use of residuals. Unbiased estimation by linear functions of squares and cross-products of residuals is shown to be equivalent to estimation by quadratic forms with an invariance property. This approach leads to alternative derivations of C.R. Rao's MIVQUE and MINQUE by using well-known results in linear model theory. Further, the method extends easily to utilize a priori knowledge of the parameter space, which ensures, for example, nonnegative estimates of variance components; when estimates are constrained to a strictly positive region, an iterative feedback procedure is made feasible."], ["Components of Variance Estimation for the Split-Plot Design", "In the balanced two-way layout split-plot design, maximum likelihood estimators and restricted maximum likelihood estimators are compared with the commonly used minimum variance unbiased estimators of variance components. Consistency problems are noted for the maximum likelihood estimators and a theorem is proved showing that the mean square errors of the restricted maximum likelihood estimators are uniformly smaller than the minimum variance unbiased estimators."], ["Approximations to Density Functions Using Pearson Curves", "This article is an expository paper to demonstrate the usefulness of Pearson curves in density estimation especially for those unaware of this early development in statistics. It is shown how to fit the curves and how very good approximate percentage points can be obtained for intractable distributions when the first four moments (or three moments and one endpoint) are known exactly (not estimated from sample data). The effectiveness of this method in density estimation is illustrated in three somewhat disparate contexts and reference is given to others. In general, the Pearson curves give an excellent approximation to the long tail of a distribution, the tail most often needed in practical work."], ["Comment on the Iterative Refinement of Least-Squares Solutions", null], ["Likelihood Methods and Nonparametric Tests", "Standard techniques of nonparametric statistics are related to likelihood procedures. In particular, rank tests and permutation tests in the regression problem are shown to be directly related to score function tests based on marginal and conditional likelihoods, respectively. The problem of estimating a population percentile is also examined from the viewpoint of marginal likelihood. These calculations tend to bring nonparametric procedures more closely in line with procedures adopted in parametric inference."], ["Optimal Experimental Designs in Two Dimensions Using Minimum Bias Estimation", null], ["Admissible Run-Contingency Type Tests for Independence and Markov Dependence", "Admissible statistical tests of fixed level are derived for the hypotheses (a) of statistical independence and (b) of Markov dependence, against the alternative of a higher-order Markov dependence. The tests, which are related to the run test and to contingency tests, are conditional procedures given a complete sufficient statistic. Comparisons are made with chi-squared tests for independence using computer simulation."], ["Estimating the Complete Sample Size from an Incomplete Poisson Sample", "Maximum likelihood estimators and a modified maximum likelihood estimator are developed for estimating the zero class from a truncated Poisson sample when the available sample size itself is a random variable. All the estimators considered here are asymptotically equivalent in the usual sense; hence their asymptotic properties are investigated in some detail theoretically as well as by making use of Monte Carlo experiments. One modified estimator appears to be best with respect to the chosen criteria. An example is given to illustrate the results obtained."], ["A Note on the Small-Sample Power Functions for Nonparametric Tests of Location in the Double Exponential Family", null], ["An Optimal Property of Principal Components in the Context of Restricted Least Squares", "A new optimal property for principal components regression is presented. In particular, it is shown that the trace of the covariance matrix for estimators obtained by deleting principal components associated with the smallest eigenvalues is at least as small as that for any other least-squares estimator with an equal or smaller number of linear restrictions. This property is useful in suggesting data transformations and determining the maximum variance reduction obtainable from the introduction of linear restrictions on the parameter space."], ["A Note on Estimating the Variance of the Sample Median", "Estimation of the variance of the sample median based on small samples is discussed, and short tables are provided to facilitate calculation of the estimates."], ["Testing for and against an Order Restriction on Multinomial Parameters", "Likelihood-ratio statistics are considered for testing a simple null hypothesis on a collection of multinomial parameters against an order-restricted alternative and for testing an order restriction against all alternatives. For the former test, the asymptotic distribution of the test statistic under the null hypothesis is a version of the chi-bar-squared distribution. This extends the work of Chacko (1966). For the latter test, homogeneity is, asymptotically, the least favorable configuration and under this hypothesis the asymptotic distribution of the test statistic has tail probabilities which are weighted averages of standard chi-squared tail probabilities."], ["On Testing a Multivariate Linear Hypothesis When the Covariance Matrix and its Inverse Have the Same Pattern", null], ["A Note on the Efficient Estimation of the Linear Expenditure System", "An efficient method of estimating the linear expenditure system (LES) by maximum likelihood is introduced. A test for insuring that parameter estimates obtained by numerical maximization satisfy the first-order conditions is given. In some experiments the new method of estimating the LES is compared to the more conventional method of estimation and is found to use significantly less computer time than the conventional method."], ["Maximum Likelihood Estimates of the Parameters of the Cauchy Distribution for Samples of Size 3 and 4", "Expressions are given for the joint maximum likelihood estimates of the location and scale parameters of a Cauchy distribution based on samples of size 3 and 4."], ["Book Reviews", null], ["Corrigenda", null], ["Editorial Board Page", "This article has no abstract"]]}