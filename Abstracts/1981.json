{"1981": [["Graphical Representation of Multivariate Data by Means of Asymmetrical Faces", "Proceeding from the idea of Chernoff (1971, 1973) of representing multivariate data by faces, a new face is proposed in which the face parameters of the left and the right side can be varied separately. The new face can be applied in the same way as the usual Chernoff face (with 36 instead of 18 representable variables). Special applications of the new face are the representation of multivariate paired comparison and the visual search for outliers. Several examples illustrate these applications. Compared with Chernoff's face, the new construction is more realistic, degenerates less, and avoids as much as possible mutual influences of the different face parameters."], ["Using Ridge Regression to Estimate Directly Lagged Effects in Marketing", "A prediction criterion for ridge regression is developed and used for estimating lagged effect patterns by means of the direct lag model. As examples, the Lydia Pinkham monthly and annual data are analyzed, showing that lag patterns can be obtained that are in agreement across time intervals."], ["A One-Factor Multivariate Time Series Model of Metropolitan Wage Rates", "The paper formulates and estimates a single-factor multivariate time series model. The model is a dynamic generalization of the multiple indicator (or factor analysis) model. It is shown to be a special case of the general state space model and can be estimated by maximum likelihood methods using the Kalman filter algorithm. The model is used to obtain estimates of the unobserved metropolitan wage rate for Los Angeles, based on observations of sectoral wages within the Standard Metropolitan Statistical Area. Hypothesis tests, model diagnostics, and out-of-sample forecasts are used to evaluate the model."], ["Modeling Demographic Relationships: An Analysis of Forecast Functions for Australian Births", "The paper discusses the problem of modeling demographic variables for the purpose of forecasting. It is argued that theory rarely provides a complete dynamic specification for the model. Two empirical model selection procedures, a time series approach (Haugh and Box 1977 and Granger and Newbold 1977) and a sequential testing procedure (Hendry and Mizon 1978), are applied to suggest final-form forecasting equations for an Australian births series, first nuptial confinements. The suggested models are then assessed by comparing their post-sample forecast performance with that of univariate ARMA type models of confinements, which are regarded as approximations to the confinements final equation model. This modeling strategy is contrasted with the method used to construct the Australian government's IMPACT demographic module."], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["Modeling Multiple Time Series with Applications", "An approach to the modeling and analysis of multiple time series is proposed. Properties of a class of vector autoregressive moving average models are discussed. Modeling procedures consisting of tentative specification, estimation, and diagnostic checking are outlined and illustrated by three real examples."], ["Projection Pursuit Regression", "A new method for nonparametric multiple regression is presented. The procedure models the regression surface as a sum of general smooth functions of linear combinations of the predictor variables in an iterative manner. It is more general than standard stepwise and stagewise regression procedures, does not require the definition of a metric in the predictor space, and lends itself to graphical interpretation."], ["Variation Diminishing Transformations: A Direct Approach to Total Positivity and its Statistical Applications", "Karlin has shown that the variation diminishing property possessed by totally positive distributions allows a unified and straightforward presentation of many basic properties of hypothesis tests. His work in fact reveals that total positivity is equivalent to a suitably formulated variation diminishing property. This largely expository article begins with the latter concept and consequently gives a more direct account of the theory. This approach avoids the extensive mathematical preliminaries previously required and isolates the more important statistical property."], ["Bayes Empirical Bayes", "A Bayesian approach is given for various kinds of empirical Bayes problems. In particular it is shown that empirical Bayes procedures are really non-Bayesian, asymptotically optimal, classical procedures for mixtures. In some situations these procedures are Bayes with respect to some prior and in other situations, there is no prior for which they are Bayes. Several examples of these concepts are given as well as a general theory showing the difference between an empirical Bayes model and a Bayes empirical Bayes model."], ["Coordinate-Free Ridge Regression Bounds", "The dependence of ridge-regression estimates on the choice of parameterization is defined with reference to the hull of all possible ridge estimates for all possible parameterizations. A reanalysis of Hoerl and Kennard's (1970) 10-factor example and Marquardt and Snee's (1975) acetylene data reveals that most conclusions depend on the parameterization."], ["Estimation Analogies in Control", "Least squares estimation and quadratic openloop optimal control share both algebra and intuition; this paper explores the duality to develop the parallels in each. Estimation results suggest control analogs to correlation measures, significance tests, distributed lags and problems of multicollinearity, tests of compatability between restrictions and data, and a version of the Kalman filter that is sometimes computationally expedient. Conversely, the control literature provides methods of incorporating certain types of inequality restrictions and a development of recursive estimation based on the Kalman filter. A by-product is a method of solving control problems using least squares computer programs."], ["Best Linear Recursive Estimation for Mixed Linear Models", "Recursive estimation techniques for fixed and completely random models are extended to mixed linear models. The Kalman filter is used to obtain recursive estimators for a two-part random model where the second random factor obeys a generalized autoregressive process. By passing to the limit in an appropriate way, recursions for the mixed model are derived."], ["Robustness of Design against Autocorrelation in Time II: Optimally, Theoretical and Numerical Results for the First-Order Autoregressive Process", "The optimum design and its efficiency relative to the uniform design for estimating the mean of a stationary First-order autoregressive process plus an independent error are characterized completely. This is related to the work of Jones (1948), Optimum designs and variances of least squares estimates are calculated numerically for the problem of estimating the slope in a simple linear regression when the errors follow the above structure, for a range of values of the sample size and the parameters of the process. Numerical results in both cases are compared with asymptotic values obtained in Bickel and Herzberg (1979), The asymptotic optimality of the uniform design is borne out."], ["Simultaneous Confidence Intervals for Functions of Variance Components in Random Models", "Interval estimation of certain functions of variance components is of interest to research workers in all fields of applications in which the variance component model is used. Confidence intervals for linear functions and ratios of variance components have been proposed by several authors. For the most part, these intervals are approximate with unknown exact probabilities associated with their coverage. In this article a technique is given for the construction of simultaneous confidence intervals for the values of all continuous functions of the variance components in a balanced, general random linear model. These confidence intervals are conservative; that is, the actual confidence level cannot be less than any preset value. The proposed technique is easy to apply as it only requires the optimization of a given continuous function of the variance components over a bounded region. Several examples of continuous functions are considered, including linear functions and ratios of variance components. Furthermore, the technique can be applied to unbalanced, random two-way classification models."], ["On Testing Equality of Two Exponential Distributions under Combined Type II Censoring", "The problem of testing equality of the scale parameters of two exponential distributions is considered under a combined sample type II censoring scheme that has been extensively treated in nonparametric inference. Sufficiency and invariance considerations lead to a pair of statistics, namely, the proportions of failure count and the total time on test of the first sample to those of the combined sample. Exact distribution and moment properties are discussed, and asymptotic joint normality under local alternatives is established in a general framework. An invariant test that maximizes the Pitman efficiency is seen to be based on the difference between these two proportions, and it is asymptotically equivalent to the likelihood ratio test."], ["Inference for Marginal Means in Contingency Tables with Conditional Independence", "Consider a three-way contingency table with factors A, B, and C. Assume factors A and B are independent for each given level of factor C. Inference procedures concerning the marginal means of the levels of factor A are studied. Maximum likelihood estimators, unbiased estimators, and uniformly minimum variance unbiased estimators are obtained. Exact variance formulas for the estimators are obtained. Large sample theory is developed and used for testing and confidence intervals. A variety of sampling models and generalizations are studied, including the case in which the number of levels of factor C is infinite. An example concerned with vaccine evaluation is given."], [null, null], ["Inadmissibility of Linearly Invariant Estimators in Truncated Parameter Spaces", "Estimation problems are considered where the actual parameter space is a strict subset of the full parameter space. A linear invariance structure is assumed and a quadratic loss function is used. Then it is shown that estimators taking values near the boundary of the parameter space are inadmissible and better estimators are presented. Applications are given in the fields of inequality constraint regression and randomized response."], ["Randomized Response Techniques for Multiple Sensitive Attributes", null], ["The Finite-Population Linear Regression Estimator and Estimators of its Variance\u2014An Empirical Study", "The usual variance estimator for the linear regression estimator of a finite population total is examined under some prediction (superpopulation) models. Its bias is compared with that of the least squares variance estimator. Also described are three bias-robust alternatives, one of which is the jackknife variance estimator. The theoretical results are supported by an empirical study in which simple and restricted random samples as well as some purposive (nonrandom) samples are drawn from six real populations. The results illustrate the need for prediction models, and the inadequacy of randomization per se, in providing a theoretical framework for robust inferences."], [null, null], ["On Asymptotic Power and Efficiency of Tests of Independence in Contingency Tables with Ordered Classifications", null], ["Distributions of Goodman and Kruskal's Gamma and Spearman's Rho in 2 \u00d7 2 Tables for Small and Moderate Sample Sizes", null], ["An Optimal Hierarchical Procedure for a Modified Binomial Group-Testing Problem", "Recently, Pfeifer and Enis proposed a new group-testing model in which a group test registers a value that represents the degree of total defectiveness in the group. They studied the class of Dorfman procedures and set up the recursive equations for an optimal Dorfman procedure. The recursive equations are solvable in tabular form in quadratic time. In this article the class of hierachical procedures, which contains the Dorfman procedures as a subclass, is studied. We show that the recursive equations for an optimal hierarchical procedure can be solved explicitly."], ["Stronger Players Need Not Win More Knockout Tournaments", "We present a counterexample to the following conjecture of F.R.K. Chung and F.K. Hwang (1978): for any knockout tournament plan and any preference scheme satisfying strong stochastic transitivity, if all assignments of players to starting positions are equally likely, then stronger players (as defined by the preference scheme) are more likely to win the tournament."], ["Optimal Selection from a Finite Sequence with Sampling Cost", null], ["A General Class of One-Sample Nonparametric Test Statistics Based on Subsamples", null], ["Entropy-Based Tests of Uniformity", "The power properties of an entropy-based test are investigated when used for testing uniformity on [0, 1]. Percentage points and power against seven alternatives are reported. Compared with other tests of uniformity, the entropy-based test possesses good power properties for many alternatives. Some asymptotic null and alternative distributions are derived. For sample sizes up to 100 the table of percentage points provides a practical guide for using this test. A theory of entropy-based tests of distributional hypotheses other than uniformity is outlined."], ["Bounds for the Covariance Matrices of Zellner's Estimator in the SUR Model and the 2SAE in a Heteroscedastic Model", "This article gives a bound for the covariance matrix of Zellner's estimator with the unrestricted sample covariance matrix in the two equations seemingly unrelated regression (SUR) model, and a bound for the covariance matrix of the two-stage Aitken estimator (2SAE) in a heteroscedastic model with two distinct variances. Some efficiencies of these estimators relative to the ordinary least squares estimator (OLSE) are also considered."], ["A New Maximum Likelihood Algorithm for Piecewise Regression", "This paper presents a piecewise regression method for continuous models containing max or min operators, or both. This method does not require knowledge of the zone in which a shift in regimes occurs. Moreover, it allows the application of analytical derivatives to maximize the likelihood function, which greatly simplifies the estimation of the model. The method proposed exhibits fast convergence and can be used for an arbitrary number of regimes and variables."], ["A Comparative Study of Instrumental Variables Estimators for Nonlinear Simultaneous Models", null], ["On the Algebraic Structures in the Construction of Confounding Plans in Mixed Factorial Designs on the Lines of White and Hultquist", "White and Hultquist (1965) developed a method of combining finite fields mapped into a finite commutative ring to provide confounding plans for mixed factorial experiments where the numbers of the levels of factors have to be prime or the power of a prime. This paper extends their procedure to cover mixed factorials where the numbers of levels of factors need to be relatively prime, and not necessarily all prime, thus covering a wider range of mixed factorial experiments amenable to the traditional way of analysis of variance suggested by White and Hultquist."], ["The Most Powerful Invariant Test of Normal versus Cauchy with Applications to Stable Alternatives", "This paper gives a derivation of the most powerful scale and location invariant test of normal versus Cauchy. A simulation study of this test shows that in testing normality versus symmetric stable alternatives it comes closer to being uniformly more powerful than any of five tests previously studied."], [null, null], ["Book Reviews", null], ["Corrigenda", null], ["Editorial Board Page", "This article has no abstract"], ["Statistics in Society: Problems Unsolved and Unformulated", "Many problems important to society have major statistical components, yet are not wholly statistical in the usual sense. Examples of such problems are discussed, and a tentative classification is proposed. The first examples are those of inconsistencies and the like in large data sets, for example, census information showing a number of women, aged 15 through 19, with 12 or more children. The second group of examples deals with ambiguity of classification, for example, of ethnic origin. Other problems discussed briefly include clarity of statistical graphics, and confidentiality. Stress is laid on novel theoretical issues posed by these problems, and also on the social or political forces that generate the problems. A professional response is proposed in which resources are sought to study with care the behavior of relevant statistical activities."], ["Predicting a Multitude of Time Series", "Principles for constructing estimators of the Stein type (shrinkage estimators) are discussed in general terms, with emphasis on underlying assumptions. The problem of parameter estimation and prediction for multiple time series is examined with these principles in mind, particularly for the case in which the number of time series is large and the number of observations from each series is small. Our results are applied to the problem of demand estimation in an inventory control setting."], ["Measures of Nominal-Ordinal Association", "Measures are formulated for summarizing the strength of association between a nominal variable and an ordered categorical variable. The measures are differences or ratios of probabilities of events concerning two types of pairs of observations. They can be used to describe the degree of difference between two or more groups on an ordinal response variable. The measures summarize and complement the results of fitting models to nominal-ordinal cross-classification tables, especially when a single structural model form cannot be found that adequately describes an entire table or set of tables."], ["Implementation of Upper Multinomial Bound Using Clustering", "The multinomial bound is a nonparametric bound for a finite population total when most elements have a value of zero and the remaining elements have positive values, such as occur in accounting and in threshold problems in the physical and biological sciences. Up to now, computational difficulties have restricted use of the multinomial bound to cases where the sample contains eight or less errors. The use of clustered errors described in this paper extends use of the multinomial bound to cases where the sample contains up to 25 errors, with only moderate loss in tightness of the bound."], ["Estimating Volumes of Remaining Fossil Fuel Resources: A Critical Review", "A number of problems arise in applying standard statistical techniques to the estimation of remaining volumes of crude oil and natural gas resources. This article reviews and criticizes past approaches, which include methods based on geology and methods that are primarily statistical in nature. Two newer approaches to the problem are described and their results summarized. It is clear that more statistical work is needed in this area."], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["Estimation of Time Series Models in the Presence of Missing Data", "A method is proposed for the estimation of models for discrete time series in the presence of missing data. Some justification is given for the use of this method over alternatives; the choice of estimator is likely to be governed by the pattern of missing data, the nature of the time series model, and computational considerations. The method's performance in estimating simple models is studied by simulations, and it is applied to a time series of pollution levels containing some missing observations."], ["On the Bias in Estimates of Forecast Mean Squared Error", "We examine the forecasting problem for a finite series of observations from either a nonseasonal or a seasonal autoregressive-moving average process. Four sources of bias in the usual estimator of forecast mean squared error are identified and analyzed for particular models using maximum likelihood and least squares parameter estimates. The usual estimator is found to be biased downwards, especially near the boundary of a stationary or invertible region, and the bias is severe for least squares estimators. An alternative estimator is proposed for the maximum likelihood case, which is shown generally to have reduced bias."], ["On the Relationship between the S Array and the Box-Jenkins Method of ARMA Model Identification", null], ["Effects of Not Knowing the Order of an Autoregressive Process on the Mean Squared Error of Prediction\u2014I", null], ["Estimation of Dynamic Models with Error Components", null], ["The Analysis of Variance Mixed Model with Allocated Observations: Application to Repeated Measurement Designs", "This article deals with layouts involving one random factor and at least one fixed factor crossed with the random factor, where the sum of the observations on each level of the random factor must equal a specified constant. The constant total for each random level can then be thought of as allocated among the levels of other factors. An allocation mixed model is proposed as a modification of the Scheff\u00e9 mixed model, which applies when there are no constant-sum constraints. It is shown that for testing several hypotheses and estimating several parameters of interest, parallel statistical methods can be applied under the Scheff\u00e9 and the allocation mixed models."], ["Two-Treatment Crossover Designs for Estimating a Variety of Effects", "The variances of contrasts among direct, residual, and cumulative treatment effects are compared for a variety of two-treatment crossover designs. Estimation of contrasts among second-order residual effects and among direct-by-period and direct-by-first-order-residual interaction effects is also considered."], ["A Constrained Least Squares Approach to the General Gauss-Markov Linear Model", null], ["High-Efficiency Estimation for the Positive Stable Laws", null], ["Estimation of the Scaling Parameter for a Kernel-Type Density Estimate", "An algorithm is given for estimation of the scaling parameter \u039b in the kernel-type density estimate derived from the Fourier integral. A Monte Carlo study of five different densities compares the integrated square error (ISE) for the resulting estimate to the ISE for the Fourier integral estimate (FIE) with mean integrated squared error (MISE) optimal \u039b and to the ISE for the normal kernel with asymptotically MISE optimal \u039b. The study shows the FIE with estimated \u039b compares favorably with the other estimates and demonstrates the asymptotic optimality of the FIE for smooth densities."], [null, null], [null, null], ["Influence Functions for Testing", null], ["Linear Functions of Concomitants of Order Statistics with Application to Nonparametric Estimation of a Regression Function", null], ["Minimum Distance Estimators for Location and Goodness of Fit", null], ["A Ranking Procedure for Partial Discriminant Analysis", "A rank procedure developed by Broffitt, Randles, and Hogg (1976) is modified to control the conditional probability of misclassification given that classification has been attempted. This modification leads to a useful solution to the two-population partial discriminant analysis problem for even moderately sized training sets."], ["Robustness of Fisher's Linear Discriminant Function under Two-Component Mixed Normal Models", "Robustness of Fisher's linear discriminant function is evaluated when the distributions of the two populations are characterized by two-component mixed normal distributions with known parameters. The results suggest that the linear discriminant function is rather robust when the two distributions do not markedly deviate from normality and are moderately distant, particularly if they are similar in shape."], ["Regression Analysis of Data from a Cluster Sample", "For the case of different regression relationships in different subgroups of a finite population, only part of which are sampled, the extended least squares estimator of any weighted average of the distinct coefficients is derived, under assumptions relating only to the first two moments of the distribution of the coefficients. Under these assumptions, the estimator is shown to be the best linear \u03be-unbiased estimator, while under further distributional assumptions, it is also the Bayesian estimator for a quadratic loss function. For the case of unknown variances a method for estimating them from the sample is proposed. The empirical estimator thus obtained is shown to perform well by a simulation comparison with the optimal estimator and with other proposed empirical estimators."], ["Some Estimators of a Population Total from Simple Random Samples Containing Large Units", "The problem considered is the estimation of the population total of some characteristic from a simple random sample containing a few large or extreme observations. The effect of these large units in the sample is to distort the estimate of the population total. It is therefore important to correct the weights for such units or deflate their values at the estimation stage once they have been sampled and identified as unusually large units. In this paper, three estimators that alter the usual sampling weights have been considered. The efficiencies of these estimators have been worked out in terms of the ratio of the mean squared error of the usual estimator of the population total to the mean squared error of these estimators. A numerical study of these estimators is also discussed."], ["Sequential Selection of the Larger of Two Normal Means", null], ["A Note on the Variance and Higher Central Moments of the Stopping Time of an SPRT", "Results are obtained on the limiting distribution and corresponding moment convergence for the (normalized) stopping time of an SPRT, as the boundaries of the continuation region become infinite. These asymptotic results suggest a certain approximation for the variance of the stopping time, which is compared with some Monte Carlo results of Cox and Roseberry (1966) and an approximation due to Ghosh (1969), in the case of testing a normal mean with known variance. The approximation appears to be good provided that the mean of the log-likelihood ratio is not too close to zero."], ["The EM Approach to the Multiple Indicators and Multiple Causes Model via the Estimation of the Latent Variable", "This article considers both likelihood and Bayesian estimation procedures for a model with multiple indicators and multiple causes of a single unobservable latent variable. The model is complicated by its reduced form, which displays a mixture of econometric and psychometric themes. We avoid this complexity via the estimation of the unobservable latent variable through direct use of the original structural form. This approach not only provides maximum likelihood estimates that are equivalent to those derived from the reduced form, but it also permits a feasible Bayesian approach, which would be technically complex to execute otherwise."], ["A Class of Variate Transformations Causing Unbounded Likelihood", "Hill (1963) proved the existence of paths in the parameter space of the three-parameter lognormal distribution along which the likelihood for any given sample tends to infinity. Lambert (1970) considered a similar phenomenon in the case of the four-parameter lognormal distribution. It is shown that this anomaly is caused by the nature of the variate transformations used and not by the normal distribution itself."], ["A Monte Carlo Study of Some Two-Sample Rank Tests with Censored Data", "The powers of several nonparametric tests for the two-sample problem with censored data are compared by simulation. The tests studied include Gehan's, Efron's, and Peto's, and Prentice's generalized Wilcoxon tests, along with the logrank test. The test with the greatest power changes with the sample sizes, censoring mechanism, and distribution of the random variables. The test that performed the best overall was the Peto-Prentice generalized Wilcoxon statistic with an asymptotic variance estimate."], [null, null], ["On a Multivariate Analog of Studentized Range Test", null], ["Kolmogorov Statistics for Tests of Fit for the Extreme-Value and Weibull Distributions", null], ["Multiple Runs Distributions: Recurrences and Critical Values", "Most traditional applications of runs tests have entailed bivariate runs distributions. Extensions to more general runs tests for randomness have been hindered by the lack of exact critical values for distributions with more than two kinds of elements. Combinatorial recurrences that can be used to compute exact significance levels for small sample sizes are presented for runs distributions for \u03bd \u2265 2 kinds of elements. Critical values for small sample sizes are tabled for \u03bd = 2(1)6. More extensive tables are available from the author."], ["Approximating the Moments and Distribution of the Likelihood Ratio Statistic for Multinomial Goodness of Fit", null], ["Book Reviews", null], ["Editorial Board Page", "This article has no abstract"], ["The Analysis of Categorical Data from Complex Sample Surveys: Chi-Squared Tests for Goodness of Fit and Independence in Two-Way Tables", null], ["Covariance Analysis of Censored Survival Data Using Log-Linear Analysis Techniques", "This paper unites two different fields, survival and contingency table analysis, in a single analytical framework based on the log-linear model. We demonstrate that many currently popular approaches to modeling survival data, including the approaches of Glasser (1967), Cox (1972), Breslow (1972, 1974), and Holford (1976), can be handled by using existing computer packages developed for the log-linear analysis of contingency table data. More important, we demonstrate that the log-linear modeling system used to characterize counted data structures directly characterizes survival data as well. Counted data methodologies for testing and estimation are also applicable here. Much of the theoretical basis for this work has been independently derived by Holford (1980) and Aitkin and Clayton (1980). The emphasis in this paper is not to develop new methodologies, but rather to present new uses and interpretations for already familiar methodologies."], ["Closure of the Newman-Keuls Multiple Comparisons Procedure", "Closure of the family of hypotheses tested by the Newman-Keuls procedure has been proposed in order to avoid excessive Type I errors. This proposal is examined in some detail, and a practical procedure for carrying it out is described and programmed in FORTRAN. The relation of such closure to other multiple comparison procedures is discussed, and its relatively high power is pointed out."], ["The Grouping Problem and Beef Quality Standards", "Methods of grouping the elements of a population for descriptive convenience are illustrated on the U.S. Department of Agriculture's beef grading system. A combination of grouping and response surface methods is shown to be more appropriate than methods used in the past to analyze the beef standards."], ["Seasonal Patterns of Fertility Measures: Theory and Data", "Seasonal patterns of five measures of reproduction in a population of married women are considered: marital fertility rate, pregnancy prevalence, mean open birth interval, mean closed birth interval-birth, and mean closed birth interval-woman. In a model the fertility rate is assumed to follow a known trigonometric curve; then the lag and relative variability of the other measures are considered in comparison with the fertility rate curve. The predictions from this theoretical work, when compared with observed patterns and trigonometric regression results for each measure in data from Bangladesh, are shown to be quite accurate. Implications for fertility analyses are discussed."], ["Representing Points in Many Dimensions by Trees and Castles", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["Graphics for the Multivariate Two-Sample Problem", "Some graphical methods for comparing multivariate samples are presented. These methods are based on minimal spanning tree techniques developed for multivariate two-sample tests. The utility of these methods is illustrated through examples using both real and artificial data."], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["An Analysis of Transformations Revisited", null], ["Censored Data and the Bootstrap", "This article concerns setting standard errors and confidence intervals for the parameters of an unknown distribution when the data is subject to right censoring. The bootstrap, which is an elaboration of the jackknife, provides a general method for answering such questions. The validity of bootstrap methods is investigated using real data, computer simulations, and, in the final section, brief theoretical considerations."], ["Association Models and Canonical Correlation in the Analysis of Cross-Classifications Having Ordered Categories", "The association models considered in Goodman (1979a) for the analysis of cross-classifications having ordered categories are presented in a somewhat different form in the present article to facilitate comparison of the results obtained using these models with those obtained using the earlier canonical correlation approach. Both the association models and the canonical correlation approach can provide meaningful scores for the row and column categories, and these scores can be used to partition into relevant components the usual chi-squared statistic for testing the null hypothesis of statistical independence between the row classification and column classification. However, while the usual procedure for testing the statistical significance of chi-squared components is invalid when these components are based on the canonical correlations, a corresponding procedure is valid when these components are obtained with the association models. The components of association obtained with the association models can be tested in a straightforward manner."], ["An Interpretation of Completeness and Basu's Theorem", null], ["Estimation in Covariance Components Models", "Estimation techniques for linear covariance components models are developed and illustrated with special emphasis on explaining computational processes. The estimation of fixed and random effects when the variances and covariances are known is presented in Bayesian terms, Point estimates of the unknown variances and covariances are computed using the EM algorithm for maximum likelihood estimation from incomplete data. The techniques are illustrated with data on law schools, field mice, and professional football teams."], ["Robust Estimation of Dispersion Matrices and Principal Components", "This paper uses Monte Carlo methods to compare the performances of several robust procedures for estimating a correlation matrix and its principal components. The estimators are formed either from separate bivariate analyses or by simultaneous manipulation of all variables by using techniques such as multivariate trimming and M-estimation. The M-estimators stand up exceptionally well. They and the multivariate trimming procedure are especially effective at estimating the principal components, including a near singularity. However, the M-estimators can break down relatively easily when the dimensionality is large and the outliers are asymmetric. With missing data, the element-wise approach becomes more attractive."], ["A Comparison of Tests of the Independence of Two Covariance-Stationary Time Series", "The approximate slopes of several tests of the independence of two covariance stationary time series are derived and compared. It is shown that the approximate slopes of regression tests are at least as great as those based on the residuals of univariate ARIMA models, and that there are cases in which the former are arbitrarily great while the latter are arbitrarily small. These analytical findings are supported by a Monte Carlo study that shows that in samples of size 100 and 250 the asymptotic distribution theory under the null hypothesis is adequate for all tests, but under alternatives to the null hypothesis the rate of Type II error for the test based on ARIMA model residuals is often more than double that of the regression tests."], ["A Seasonal Adjustment Principle and a Seasonal Adjustment Method Derived from This Principle", "The decomposition of a given time series into trend, seasonal component, and irregular component is formulated as a minimization problem. The trend is chosen such that it is as smooth as possible; the seasonal component is chosen such that it exhibits a seasonal pattern as stable as possible; and the trend and seasonal components are jointly chosen such that the given time series is explained as well as possible by these two components; that is, the irregular component is minimized."], ["On Some Fourier Methods for Inference", null], ["Consistency of Single Linkage for High-Density Clusters", null], ["Complexity: An Interpretability Criterion for Multiple Comparisons", null], ["On Partitioning a Sample with Binary-Type Questions in Lieu of Collecting Observations", null], ["Marginalization and Linear Opinion Pools", "Suppose a decision maker has asked a group of experts to assess subjective probability distributions over some space, and he wishes to find a consensus probability distribution as a function of these. The assumption that finding the consensus distribution commutes with marginalization of the distributions implies that the consensus must be found using a linear opinion pool (weighted average), provided the space being considered contains three or more points. Some of the consequences of this result are discussed."], ["A Necessary and Sufficient Condition for Reaching a Consensus Using DeGroot's Method", null], ["Consequences and Detection of Misspecified Nonlinear Regression Models", "Under general conditions given here, the least squares estimator for the parameters of a misspecified nonlinear model converge strongly to the parameters of a (weighted) least squares approximation to the true model. With additional conditions, the least squares estimator is asymptotically normal. A new, specification-robust estimator of the covariance matrix is obtained, which simplifies to the usual estimator when the model is correct up to an independent additive error. The properties of the approximation and the covariance estimator are exploited to yield new tests for model misspecification. These results are applied to two examples in economics."], ["Efficiencies of Nine Two-Phase Ratio Estimators for the Mean", null], ["Maximal Deviation between Sample and Population Means in Finite Populations", "Bounds are presented for the maximal deviation in finite populations between sample and population means in units of (a) the population mean deviation, (b) the population range, and (c) the population mean, extending previous results for the population standard deviation. The efficiency of sampling is illustrated by various sample size calculations. The effect of symmetry on these bounds is considered. An application is made, in the symmetric case, to the expression for the bias of the ratio estimator."], ["A Variant of the Acceptance-Rejection Method for Computer Generation of Random Variables", "A variant of the common acceptance-rejection method for generating random variables guarantees that steps are not repeated. This approach affords considerable flexibility in tailoring the method efficiently to the specified density. An algorithm for generating Cauchy random variables illustrates the use of this approach."], ["A Confidence Bound Approach to Choosing the Biasing Parameter in Ridge Regression", null], ["Mean Squared Error Properties of Generalized Ridge Estimators", "Mean squared errors are derived and examined for a number of generalized ridge (GR) regression estimators, and the estimators are compared in a number of specific regression models. The potential of GR estimators is discussed."], ["Estimation of the Minimum of a Function Using Order Statistics", null], ["Invariant Sequential Estimation of the Exponential Mean Life from the Ordered Observations", "This paper derives the best invariant sequential estimate of exponential mean life for the situation where observations become available sequentially. If a cost function proportional to the observed time and relative squared error loss are adopted, it turns out that the best invariant rule is a fixed sample size rule."], ["Bounds for the Confidence Coefficients of Outer and Inner Confidence Intervals for Quantile Intervals", "In this article, bounds for the confidence coefficients of outer and inner confidence intervals for quantile intervals are obtained using properties of convex functions. The bounds obtained here are sharper than the bounds given in Krewski (1976) and Reiss and Ruschendorf (1976)."], ["Asymptotic Expansions of the Distribution of an Improved Limited Information Maximum Likelihood Estimator", "An improvement of the limited information maximum likelihood (LIML) estimator was proposed by Morimune (1978). In this note two asymptotic expansions of the distribution of the improved estimator are derived, both for large sample size and for large values of the noncentrality parameter. The improved estimator uniformly dominates the LIML estimator in terms of the probability of concentration around the true coefficient for both the parameter sequences. The distributions of the coefficient of income multiplier in the consumption function are also derived."], ["A Gaussian Approximation to the Distribution of the Sample Variance for Nonnormal Populations", "A Gaussian approximation to the distribution of the sample variance is developed using the Wilson-Hilferty (1931) approach. This approximation is compared with the well-known approximations due to Box (1953), Roy and Tiku (1962), and Tan and Wong (1977) by taking the exponential, Laplace, uniform, product normal, Weibull, lognormal, Tine, logistic, and various mixtures of normal distributions as parent populations. The Gaussian approximation, which can be used for probabilities as well as percentiles, compares favorably with the other three approximations."], ["On Optimal Choice of Components for Parallel Systems", null], ["Book Reviews", null], ["Editorial Board Page", "This article has no abstract"], ["Statistical Practice in Bureaucracies", null], ["Monte Carlo Study of Three Data-Based Nonparametric Probability Density Estimators", "Although the theoretical properties of modern nonparametric probability density estimators have been studied for 25 years, there remains the practical problem of how to specify the amount of bias or smoothing in a density estimate based on a random sample. In this paper we review and evaluate three recently developed data-based algorithms that completely specify a density estimate from a random sample. Using Monte Carlo techniques, we compare the statistical accuracy of these algorithms as measured by the integrated mean squared error. In addition, we examine the sensitivity of these algorithms to outliers and estimate computer time requirements. One conclusion we draw is that the statistical accuracy of these data-based algorithms seems comparable to levels predicted by theoretical models."], ["Asymmetric Time Series", "Asymmetric time series respond to innovations with one of two different rules according to whether the innovation is positive or negative. Quoted industrial prices are apparently such a series. It has been observed that when market conditions change, quoted prices are not revised immediately. This delay operates more strongly against reductions in price quotations than against increases. A statistical model for such asymmetric times series is developed and analyzed. An estimation procedure is given as well as a statistical test of the hypothesis of symmetry versus the alternative of asymmetry. Asymmetric time series models are fit to several economic time series."], ["Optimal Grouping of Income Distribution Data", "We consider the problem of grouping income distribution data into a given number of groups such that the concealed income differences due to grouping are minimized. When income differences are measured by Gini's pairwise differences, this means minimizing the area between the grouped and ungrouped Lorenz curves. In this case, the necessary condition for optimal grouping is that each group limit be equal to the average income in its two adjacent groups. An iterative procedure for computation and applications including fractile groupings are discussed. Alternative optimal groupings based on other measures of income differences are also considered."], ["Sample Size for Logistic Regression with Small Response Probability", "The Fisher information matrix for the estimated parameters in a multiple logistic regression can be approximated by the augmented Hessian matrix of the moment-generating function for the covariates. The approximation is valid when the probability of response is small. With its use one can obtain a simple closed-form estimate of the asymptotic covariance matrix of the maximum likelihood parameter estimates, and thus approximate sample sizes needed to test hypotheses about the parameters. The method is developed for selected distributions of a single covariate and for a class of exponential-type distributions of several covariates. It is illustrated with an example concerning risk factors for coronary heart disease."], ["An Exponential Family of Probability Distributions for Directed Graphs", "Directed graph (or digraph) data arise in many fields, especially in contemporary research on structures of social relationships. We describe an exponential family of distributions that can be used for analyzing such data. A substantive rationale for the general model is presented, and several special cases are discussed along with some possible substantive interpretations. A computational algorithm based on iterative scaling procedures for use in fitting data is described, as are the results of a pilot simulation study. An example using previously reported empirical data is worked out in detail. An extension to multiple relationship data is discussed briefly."], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["An Empirical Study of the Ratio Estimator and Estimators of its Variance", "This paper reports results from an empirical study of the ratio estimator for a finite population total. From each of six real populations, 1,000 simple random samples, 1,000 restricted random samples, and three nonrandom samples of size 32 are drawn. Performance of the ratio estimator and of five estimators of its variance is compared with theoretical results generated using (a) prediction (superpopulation) models and (b) probability sampling distributions. The results, presented graphically, show that theory based on prediction models can reveal relationships that are essential in making inferences, but that are concealed in probability sampling analyses."], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Comment", null], ["Rejoinder", null], ["Estimators for the One-Way Random Effects Model with Unequal Error Variances", null], ["On the Asymptotic Distribution of Ratio and Regression Estimators", null], ["Concavity of the Log Likelihood", null], ["Polarization Test for the Multinomial Distribution", null], ["Hierarchical Log-Linear Models Not Preserved by Classification Error", "A model of Bross (1954) for classification error in 2 \u00d7 2 contingency tables is extended to higher dimensional tables. It is known (Mote and Anderson 1965) that the usual hypothesis tests of independence for a sampled two-dimensional table have the nominal significance level in the presence of misclassification. A simple criterion is given to determine which hierarchical log-linear models in higher dimensional tables do not share this property, that is, are not preserved by classification error."], [null, null], ["Multiple Three-Decision Rules for Factorial Simple Effects: Bonferroni Wins Again!", null], ["Confidence Regions Based on Methods of Combining Test Statistics", "A basic problem in statistics concerns the combination of test statistics. The most widely studied combination procedure is attributed to R.A. Fisher (1950) and is based on the product of the observed significance levels of the individual tests. Other methods include the likelihood ratio and a procedure based on the minimum significance level. In this article we consider inverting test combination methods to obtain simultaneous confidence regions for a parameter vector \u03b8. Properties of the regions thus obtained are discussed in terms of known results in the corresponding test combination framework. Several examples are presented to illustrate the procedures."], ["A Simulation Study of Some Ridge Estimators", null], ["Information about Hyperparameters in Hierarchical Models", null], ["Representation of Certain Covariance Matrices with Application to Asymptotic Efficiency", "Although maximum likelihood estimates are asymptotically efficient, they are often very hard to find. Replacement of some, but not all, of the equations in the maximum likelihood system may make it more manageable. The covariance matrices of the new estimator and of the estimating functions will have special structure in relation to the information matrix. These relationships are characterized and various properties that pertain to multiparameter efficiency are developed. Application is made to the estimation of parameters from the gamma distribution. Some new estimators are found and their efficiencies are compared."], ["Properties of Predictors for Autoregressive Time Series", null], ["Robust Rank Procedures for the Behrens-Fisher Problem", "The problem of testing for equality of the medians of two populations is considered. The standard distribution-free tests for this problem require that the two populations have the same shape to maintain their nominal significance level under the null hypothesis. A method is given to modify many of these tests so they can be used to test for equality of the medians with fewer assumptions on the shapes of the two populations. The method is demonstrated using the Mann-Whitney-Wilcoxon statistic."], ["A Nonparametric Multivariate Test for Monotone Trend with Pharmaceutical Applications", "During a drug trial, each subject may have many blood constituents measured at regular time intervals. The traditional method of evaluating such data using normal ranges has undergone much controversy in the clinical chemistry literature. We propose a new multivariate test for monotone trend based on Kendall's \u03c4 statistic as a way to test for change in blood constituents over the course of a drug experiment. The new test avoids the unrealistic assumptions and repeated testing problem of the normal range method. An example illustrates the new procedure."], [null, null], ["Simultaneous Poisson Estimators for a Priori Hypotheses about Means", null], ["Minimax Stopping Rules When the Underlying Distribution is Uniform", null], ["A Bivariate Distribution Family with Specified Marginals", "A systematic approach is given for constructing continuous bivariate distributions with specified marginals and ixed dependence measures. This approach is based on linear combinations of independent random variables and results in bivariate distributions that can attain the Fr\u00e9chet bounds. The dependence measures considered are Spearman's rho and Kendall's tau. Applications to testing for sensitivity in simulation models are discussed."], ["Betting against a Bayesian Bookie", "For a simple game, the optimal strategy for a Bayesian bettor playing against a Bayesian bookie is found. A necessary and sufficient condition for the bettor's expected winnings to be positive is given."], ["Book Reviews", null], ["Corrigenda", null], ["Editorial Board Page", "This article has no abstract"]]}